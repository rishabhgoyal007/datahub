"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[57766],{15680:(e,t,a)=>{a.d(t,{xA:()=>g,yg:()=>m});var n=a(96540);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},g=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},y=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,g=o(e,["components","mdxType","originalType","parentName"]),u=p(a),y=r,m=u["".concat(s,".").concat(y)]||u[y]||c[y]||i;return a?n.createElement(m,l(l({ref:t},g),{},{components:a})):n.createElement(m,l({ref:t},g))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=y;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[u]="string"==typeof e?e:r,l[1]=o;for(var p=2;p<i;p++)l[p]=a[p];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}y.displayName="MDXCreateElement"},81925:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>g,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>p,toc:()=>u});a(96540);var n=a(15680);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}const o={title:"Google Dataplex Source - Developer Guide",slug:"/metadata-ingestion/src/datahub/ingestion/source/dataplex",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/README.md"},s="Google Dataplex Source - Developer Guide",p={unversionedId:"metadata-ingestion/src/datahub/ingestion/source/dataplex/README",id:"metadata-ingestion/src/datahub/ingestion/source/dataplex/README",title:"Google Dataplex Source - Developer Guide",description:"This directory contains the DataHub connector for Google Dataplex.",source:"@site/genDocs/metadata-ingestion/src/datahub/ingestion/source/dataplex/README.md",sourceDirName:"metadata-ingestion/src/datahub/ingestion/source/dataplex",slug:"/metadata-ingestion/src/datahub/ingestion/source/dataplex",permalink:"/docs/metadata-ingestion/src/datahub/ingestion/source/dataplex",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/README.md",tags:[],version:"current",frontMatter:{title:"Google Dataplex Source - Developer Guide",slug:"/metadata-ingestion/src/datahub/ingestion/source/dataplex",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/README.md"}},g={},u=[{value:"Implementation Overview",id:"implementation-overview",level:2},{value:"Architecture",id:"architecture",level:3},{value:"Entity Mapping",id:"entity-mapping",level:3},{value:"Dual API Architecture",id:"dual-api-architecture",level:3},{value:"1. <strong>Entries API (Universal Catalog)</strong> - Primary, Default Enabled",id:"1-entries-api-universal-catalog---primary-default-enabled",level:4},{value:"2. <strong>Entities API (Lakes/Zones)</strong> - Optional, Default Disabled",id:"2-entities-api-lakeszones---optional-default-disabled",level:4},{value:"API Coordination",id:"api-coordination",level:4},{value:"Key Components",id:"key-components",level:3},{value:"Capabilities",id:"capabilities",level:3},{value:"Development Setup",id:"development-setup",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Install Development Dependencies",id:"install-development-dependencies",level:3},{value:"Run Linting",id:"run-linting",level:3},{value:"Run Tests",id:"run-tests",level:3},{value:"Project Structure",id:"project-structure",level:2},{value:"Implementation Notes",id:"implementation-notes",level:2},{value:"URN Generation",id:"urn-generation",level:3},{value:"Container Linking",id:"container-linking",level:3},{value:"Custom Properties",id:"custom-properties",level:3},{value:"Parallel Processing",id:"parallel-processing",level:3},{value:"Entries API Implementation",id:"entries-api-implementation",level:3},{value:"Entry Group Discovery",id:"entry-group-discovery",level:4},{value:"Entry Processing",id:"entry-processing",level:4},{value:"Schema Extraction from Entries",id:"schema-extraction-from-entries",level:4},{value:"Custom Properties from Entry Metadata",id:"custom-properties-from-entry-metadata",level:4},{value:"Location Requirements",id:"location-requirements",level:4},{value:"Memory Optimization",id:"memory-optimization",level:4},{value:"Lineage Extraction",id:"lineage-extraction",level:3},{value:"Architecture",id:"architecture-1",level:4},{value:"How It Works",id:"how-it-works",level:4},{value:"Configuration Options",id:"configuration-options",level:4},{value:"Lineage API Integration",id:"lineage-api-integration",level:4},{value:"Data Structures",id:"data-structures",level:4},{value:"Limitations",id:"limitations",level:4},{value:"Contributing",id:"contributing",level:2},{value:"References",id:"references",level:2}],c={toc:u},y="wrapper";function m(e){var{components:t}=e,a=l(e,["components"]);return(0,n.yg)(y,i(function(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},n=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),n.forEach((function(t){r(e,t,a[t])}))}return e}({},c,a),{components:t,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"google-dataplex-source---developer-guide"},"Google Dataplex Source - Developer Guide"),(0,n.yg)("p",null,"This directory contains the DataHub connector for Google Dataplex."),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"For user documentation, setup instructions, and configuration examples, see the Dataplex connector documentation at docs.datahub.com.")),(0,n.yg)("h2",{id:"implementation-overview"},"Implementation Overview"),(0,n.yg)("p",null,"This connector extracts metadata from Google Dataplex entities (discovered tables/filesets) and maps them to DataHub datasets using ",(0,n.yg)("strong",{parentName:"p"},"source platform URNs")," (BigQuery, GCS, etc.) to align with native source connectors."),(0,n.yg)("h3",{id:"architecture"},"Architecture"),(0,n.yg)("p",null,"The connector follows the pattern established by the ",(0,n.yg)("inlineCode",{parentName:"p"},"bigquery_v2")," source:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Uses Google Cloud client libraries (",(0,n.yg)("inlineCode",{parentName:"li"},"google-cloud-dataplex"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"google-cloud-datacatalog-lineage"),")"),(0,n.yg)("li",{parentName:"ul"},"Supports both service account credentials and Application Default Credentials"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Generates datasets with source platform URNs")," (no Dataplex-specific containers)"),(0,n.yg)("li",{parentName:"ul"},"Links BigQuery entities to BigQuery dataset containers for consistent navigation"),(0,n.yg)("li",{parentName:"ul"},"Preserves Dataplex context (lake, zone, asset) as custom properties"),(0,n.yg)("li",{parentName:"ul"},"Supports parallel zone processing with ",(0,n.yg)("inlineCode",{parentName:"li"},"ThreadedIteratorExecutor"))),(0,n.yg)("h3",{id:"entity-mapping"},"Entity Mapping"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Dataplex Resource"),(0,n.yg)("th",{parentName:"tr",align:null},"DataHub Entity Type"),(0,n.yg)("th",{parentName:"tr",align:null},"URN Platform"),(0,n.yg)("th",{parentName:"tr",align:null},"Container"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Entity (BigQuery)"),(0,n.yg)("td",{parentName:"tr",align:null},"Dataset"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"bigquery")),(0,n.yg)("td",{parentName:"tr",align:null},"BigQuery dataset container")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Entity (GCS)"),(0,n.yg)("td",{parentName:"tr",align:null},"Dataset"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"gcs")),(0,n.yg)("td",{parentName:"tr",align:null},"None (matches GCS connector)")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Lake/Zone/Asset"),(0,n.yg)("td",{parentName:"tr",align:null},"N/A"),(0,n.yg)("td",{parentName:"tr",align:null},"N/A"),(0,n.yg)("td",{parentName:"tr",align:null},"Preserved as custom properties only")))),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Key Design Decision"),': Dataplex entities use their source platform URNs instead of "dataplex" platform URNs. This ensures:'),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Entities discovered by Dataplex appear in the same containers as entities from native BigQuery/GCS connectors"),(0,n.yg)("li",{parentName:"ul"},"No duplication when running multiple connectors (same URN = same entity)"),(0,n.yg)("li",{parentName:"ul"},"Consistent user experience regardless of discovery method"),(0,n.yg)("li",{parentName:"ul"},"Dataplex context is preserved via custom properties for traceability")),(0,n.yg)("h3",{id:"dual-api-architecture"},"Dual API Architecture"),(0,n.yg)("p",null,"The connector supports extracting metadata from two complementary Google Cloud APIs:"),(0,n.yg)("h4",{id:"1-entries-api-universal-catalog---primary-default-enabled"},"1. ",(0,n.yg)("strong",{parentName:"h4"},"Entries API (Universal Catalog)")," - Primary, Default Enabled"),(0,n.yg)("p",null,"The Entries API accesses Google Cloud's Universal Catalog, which provides a centralized view of metadata across Google Cloud resources."),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Key Characteristics:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"System-managed entry groups"),": ",(0,n.yg)("inlineCode",{parentName:"li"},"@bigquery"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"@pubsub"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"@datacatalog"),", etc."),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Comprehensive coverage"),": Automatically discovers BigQuery tables, Pub/Sub topics, and other resources"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Multi-region access"),": Requires multi-region locations (",(0,n.yg)("inlineCode",{parentName:"li"},"us"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"eu"),", ",(0,n.yg)("inlineCode",{parentName:"li"},"asia"),") to access system entry groups"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Richer metadata"),": Provides schema information and detailed aspects")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"When to use:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"\u2705 Discovering all BigQuery tables across projects"),(0,n.yg)("li",{parentName:"ul"},"\u2705 Accessing system-managed resources"),(0,n.yg)("li",{parentName:"ul"},"\u2705 Getting the most complete metadata available"),(0,n.yg)("li",{parentName:"ul"},"\u2705 ",(0,n.yg)("strong",{parentName:"li"},"Recommended for most users"))),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Configuration:")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'include_entries: true # Default\nentries_location: "us" # Multi-region required for system entry groups\n')),(0,n.yg)("h4",{id:"2-entities-api-lakeszones---optional-default-disabled"},"2. ",(0,n.yg)("strong",{parentName:"h4"},"Entities API (Lakes/Zones)")," - Optional, Default Disabled"),(0,n.yg)("p",null,"The Entities API accesses Dataplex's lake and zone structure, providing entity-level metadata for resources managed through Dataplex."),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Key Characteristics:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Lake/zone hierarchy"),": Organized by Dataplex lakes and zones"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Discovered assets"),": Tables and filesets explicitly added to Dataplex"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Regional access"),": Uses specific regional locations (",(0,n.yg)("inlineCode",{parentName:"li"},"us-central1"),", etc.)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Dataplex context"),": Direct lake/zone/asset association")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"When to use:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Use if you need entity-level details specific to lakes/zones not available in Entries API"),(0,n.yg)("li",{parentName:"ul"},"Can be used alongside Entries API (duplicates are automatically handled)")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Configuration:")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'include_entities: true # Optional\nlocation: "us-central1" # Regional location for entities\n')),(0,n.yg)("h4",{id:"api-coordination"},"API Coordination"),(0,n.yg)("p",null,"When both APIs are enabled:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Processing Order"),": Entities API \u2192 Entries API"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Aspect Replacement"),": Entries completely replace entity aspects for the same resource (same URN)"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Source of Truth"),": Universal Catalog (Entries API) takes precedence"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Data Loss"),": Entity custom properties (lake, zone, asset) are LOST when entries overwrite")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"\u26a0\ufe0f Important Limitation:")),(0,n.yg)("p",null,"When the same table is discovered by both APIs, DataHub's aspect-level replacement means:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"\u2705 Entry metadata (schema, entry custom properties) is preserved"),(0,n.yg)("li",{parentName:"ul"},"\u274c Entity metadata (lake, zone, asset custom properties) is ",(0,n.yg)("strong",{parentName:"li"},"completely lost"))),(0,n.yg)("p",null,"This is DataHub's standard behavior (not a bug). Aspects are replaced atomically."),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Recommendation:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Use ",(0,n.yg)("strong",{parentName:"li"},"Entries API only")," (default) for most use cases"),(0,n.yg)("li",{parentName:"ul"},"Use ",(0,n.yg)("strong",{parentName:"li"},"Entities API only")," if you need lake/zone organizational context"),(0,n.yg)("li",{parentName:"ul"},"Only use both if APIs discover ",(0,n.yg)("strong",{parentName:"li"},"non-overlapping datasets"))),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Example with both APIs (not recommended for overlapping data):")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: dataplex\n  config:\n    project_ids: ["my-project"]\n\n    # Entries API (primary)\n    include_entries: true\n    entries_location: "us"\n\n    # Entities API (optional - WARNING: overlapping tables lose entity context)\n    include_entities: true\n    location: "us-central1"\n')),(0,n.yg)("h3",{id:"key-components"},"Key Components"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},(0,n.yg)("a",{parentName:"strong",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/dataplex.py"},"dataplex.py")),": Main source implementation with dual API extraction logic"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},(0,n.yg)("a",{parentName:"strong",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/dataplex_config.py"},"dataplex_config.py")),": Configuration models using Pydantic"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},(0,n.yg)("a",{parentName:"strong",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/dataplex_report.py"},"dataplex_report.py")),": Reporting and metrics tracking"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},(0,n.yg)("a",{parentName:"strong",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/dataplex_helpers.py"},"dataplex_helpers.py")),": Helper functions for URN generation and type mapping"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},(0,n.yg)("a",{parentName:"strong",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/dataplex_lineage.py"},"dataplex_lineage.py")),": Lineage extraction using Dataplex Lineage API")),(0,n.yg)("h3",{id:"capabilities"},"Capabilities"),(0,n.yg)("p",null,"The connector implements the following DataHub capabilities:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"SCHEMA_METADATA"),": Schema information from discovered entities"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"LINEAGE_COARSE"),": Table-level lineage extraction via Dataplex Lineage API (when enabled)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Platform Alignment"),": Entities use source platform URNs (BigQuery, GCS) and containers")),(0,n.yg)("h2",{id:"development-setup"},"Development Setup"),(0,n.yg)("h3",{id:"prerequisites"},"Prerequisites"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Python 3.8+"),(0,n.yg)("li",{parentName:"ol"},"DataHub development environment set up"),(0,n.yg)("li",{parentName:"ol"},"Access to a GCP project with Dataplex enabled")),(0,n.yg)("h3",{id:"install-development-dependencies"},"Install Development Dependencies"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},"cd metadata-ingestion\n./scripts/install_deps.sh\n")),(0,n.yg)("h3",{id:"run-linting"},"Run Linting"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},"./gradlew :metadata-ingestion:lintFix\n")),(0,n.yg)("h3",{id:"run-tests"},"Run Tests"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-bash"},"./gradlew :metadata-ingestion:testQuick\n")),(0,n.yg)("h2",{id:"project-structure"},"Project Structure"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre"},"dataplex/\n\u251c\u2500\u2500 __init__.py                   # Package exports\n\u251c\u2500\u2500 dataplex.py                   # Main source implementation\n\u251c\u2500\u2500 dataplex_config.py            # Configuration classes\n\u251c\u2500\u2500 dataplex_report.py            # Reporting and metrics\n\u251c\u2500\u2500 dataplex_helpers.py           # Helper functions and utilities\n\u251c\u2500\u2500 dataplex_lineage.py           # Lineage extraction\n\u251c\u2500\u2500 README.md                     # This file (developer guide)\n\u251c\u2500\u2500 TEST_GUIDE.md                 # Testing documentation\n\u251c\u2500\u2500 TESTING.md                    # Test implementation details\n\u2514\u2500\u2500 example_code/                 # Reference examples and experiments\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 dataplex_client.py\n    \u251c\u2500\u2500 generate_sample_lineage.py  # Script to create sample lineage\n    \u2514\u2500\u2500 dataplex_implementation.md\n")),(0,n.yg)("h2",{id:"implementation-notes"},"Implementation Notes"),(0,n.yg)("h3",{id:"urn-generation"},"URN Generation"),(0,n.yg)("p",null,"Entities are generated using ",(0,n.yg)("strong",{parentName:"p"},"source platform URNs")," for consistency with native connectors:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"BigQuery Entities"),": ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:dataset:(urn:li:dataPlatform:bigquery,{project}.{dataset}.{table},PROD)")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"GCS Entities"),": ",(0,n.yg)("inlineCode",{parentName:"li"},"urn:li:dataset:(urn:li:dataPlatform:gcs,{bucket}/{path},PROD)"))),(0,n.yg)("p",null,"The connector uses ",(0,n.yg)("inlineCode",{parentName:"p"},"make_dataset_urn_with_platform_instance()")," with the source platform determined by querying the Dataplex asset."),(0,n.yg)("h3",{id:"container-linking"},"Container Linking"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"BigQuery entities"),": Linked to BigQuery dataset containers using ",(0,n.yg)("inlineCode",{parentName:"li"},"BigQueryDatasetKey")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"GCS entities"),": No container (matches GCS connector behavior)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Implementation"),": Self-contained ",(0,n.yg)("inlineCode",{parentName:"li"},"make_bigquery_dataset_container_key()")," helper in ",(0,n.yg)("inlineCode",{parentName:"li"},"dataplex_helpers.py"))),(0,n.yg)("h3",{id:"custom-properties"},"Custom Properties"),(0,n.yg)("p",null,"Dataplex context is preserved on each dataset via custom properties:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'custom_properties = {\n    "dataplex_ingested": "true",\n    "dataplex_lake": lake_id,\n    "dataplex_zone": zone_id,\n    "dataplex_entity_id": entity_id,\n    "dataplex_zone_type": zone.type_.name,\n    "data_path": entity.data_path,\n    "system": entity.system.name,\n    "format": entity.format.format_.name,\n}\n')),(0,n.yg)("h3",{id:"parallel-processing"},"Parallel Processing"),(0,n.yg)("p",null,"Entity extraction is parallelized at the zone level using ",(0,n.yg)("inlineCode",{parentName:"p"},"ThreadedIteratorExecutor"),":"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Configurable via ",(0,n.yg)("inlineCode",{parentName:"li"},"max_workers")," config option (default: 10)"),(0,n.yg)("li",{parentName:"ul"},"Each zone's entities are processed by a worker thread"),(0,n.yg)("li",{parentName:"ul"},"Thread-safe locks protect shared data structures (asset metadata, zone metadata, entity tracking)")),(0,n.yg)("h3",{id:"entries-api-implementation"},"Entries API Implementation"),(0,n.yg)("p",null,"The Entries API (Universal Catalog) extraction provides comprehensive metadata discovery:"),(0,n.yg)("h4",{id:"entry-group-discovery"},"Entry Group Discovery"),(0,n.yg)("p",null,"The connector discovers entry groups using the Universal Catalog API:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# List entry groups in project/location\nparent = f"projects/{project_id}/locations/{entries_location}"\nentry_groups_request = ListEntryGroupsRequest(parent=parent)\nentry_groups = catalog_client.list_entry_groups(request=entry_groups_request)\n')),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"System-managed entry groups")," (like ",(0,n.yg)("inlineCode",{parentName:"p"},"@bigquery"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"@pubsub"),") contain automatically discovered resources and require multi-region locations (",(0,n.yg)("inlineCode",{parentName:"p"},"us"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"eu"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"asia"),")."),(0,n.yg)("h4",{id:"entry-processing"},"Entry Processing"),(0,n.yg)("p",null,"For each entry group, the connector:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Lists entries")," in the group"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Fetches full details")," with ",(0,n.yg)("inlineCode",{parentName:"li"},"EntryView.ALL")," to get schema and aspects"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Extracts fully qualified name (FQN)")," from entry aspects"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Determines source platform")," from FQN prefix (e.g., ",(0,n.yg)("inlineCode",{parentName:"li"},"bigquery:")," \u2192 platform=",(0,n.yg)("inlineCode",{parentName:"li"},"bigquery"),")"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Generates source platform URN")," for consistency with native connectors")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# Extract FQN from entry aspects\nfqn = entry.fully_qualified_name  # e.g., "bigquery:project.dataset.table"\n\n# Parse platform and resource path\nplatform, resource_path = fqn.split(":", 1)  # "bigquery", "project.dataset.table"\n\n# Generate URN using source platform\ndataset_urn = make_dataset_urn_with_platform_instance(\n    platform=platform,\n    name=resource_path,\n    platform_instance=None,\n    env=env,\n)\n')),(0,n.yg)("h4",{id:"schema-extraction-from-entries"},"Schema Extraction from Entries"),(0,n.yg)("p",null,"The Entries API provides rich schema metadata through entry aspects:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'# Extract schema from entry aspects\nfor aspect in entry.aspects:\n    if aspect.type_ == "schema":\n        # Parse schema aspect data\n        schema_aspect = aspect.value\n        # Convert to DataHub SchemaMetadata\n        schema_metadata = extract_schema_from_entry_aspects(entry, ...)\n')),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Schema fields extracted:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Column names and types"),(0,n.yg)("li",{parentName:"ul"},"Column descriptions"),(0,n.yg)("li",{parentName:"ul"},"Nullability constraints"),(0,n.yg)("li",{parentName:"ul"},"Data type mappings (BigQuery \u2192 DataHub standard types)")),(0,n.yg)("h4",{id:"custom-properties-from-entry-metadata"},"Custom Properties from Entry Metadata"),(0,n.yg)("p",null,"Entry metadata is preserved as custom properties:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'custom_properties = {\n    "dataplex_ingested": "true",\n    "dataplex_entry_id": entry_id,\n    "dataplex_entry_group": entry_group_id,\n    "entry_source_system": entry.entry_source.system,\n    "entry_type": entry.entry_type,\n    "fully_qualified_name": fqn,\n}\n')),(0,n.yg)("h4",{id:"location-requirements"},"Location Requirements"),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Critical"),": The ",(0,n.yg)("inlineCode",{parentName:"p"},"entries_location")," config must be a ",(0,n.yg)("strong",{parentName:"p"},"multi-region location")," (",(0,n.yg)("inlineCode",{parentName:"p"},"us"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"eu"),", ",(0,n.yg)("inlineCode",{parentName:"p"},"asia"),") to access system-managed entry groups:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'# \u2705 Correct - multi-region for system entry groups\nentries_location: "us"\n\n# \u274c Incorrect - regional locations only have placeholder entries\nentries_location: "us-central1"  # Will miss BigQuery tables!\n')),(0,n.yg)("p",null,"The connector validates this and warns if a regional location is detected."),(0,n.yg)("h4",{id:"memory-optimization"},"Memory Optimization"),(0,n.yg)("p",null,"Entries are processed with batched emission to prevent memory issues:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"# Batch entries emission\nif len(cached_entries_mcps) >= batch_size:\n    # Emit batch to DataHub\n    for mcp in cached_entries_mcps:\n        yield mcp.as_workunit()\n    # Clear cache\n    cached_entries_mcps.clear()\n")),(0,n.yg)("p",null,"This ensures memory usage stays bounded even with 50k+ entries."),(0,n.yg)("h3",{id:"lineage-extraction"},"Lineage Extraction"),(0,n.yg)("p",null,"The connector extracts lineage using Google's Data Lineage API:"),(0,n.yg)("h4",{id:"architecture-1"},"Architecture"),(0,n.yg)("p",null,"The lineage extraction follows the pattern from ",(0,n.yg)("inlineCode",{parentName:"p"},"bigquery_v2"),":"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},(0,n.yg)("a",{parentName:"strong",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dataplex/dataplex_lineage.py"},"dataplex_lineage.py")),": ",(0,n.yg)("inlineCode",{parentName:"li"},"DataplexLineageExtractor")," class"),(0,n.yg)("li",{parentName:"ul"},"Queries Dataplex Lineage API using ",(0,n.yg)("inlineCode",{parentName:"li"},"LineageClient")),(0,n.yg)("li",{parentName:"ul"},"Builds internal lineage maps with ",(0,n.yg)("inlineCode",{parentName:"li"},"LineageEdge")," data structures"),(0,n.yg)("li",{parentName:"ul"},"Generates DataHub ",(0,n.yg)("inlineCode",{parentName:"li"},"UpstreamLineageClass")," aspects")),(0,n.yg)("h4",{id:"how-it-works"},"How It Works"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Entity Tracking"),": As entities are processed, their IDs are tracked"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Lineage Query"),": After entity extraction, queries ",(0,n.yg)("inlineCode",{parentName:"li"},"search_links")," API"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Map Building"),": Constructs lineage maps from upstream/downstream relationships"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Workunit Generation"),": Creates DataHub lineage workunits"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Emission"),": Yields workunits to be ingested into DataHub")),(0,n.yg)("h4",{id:"configuration-options"},"Configuration Options"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"# Enable/disable lineage extraction\nextract_lineage: bool = True  # Default: True\n")),(0,n.yg)("h4",{id:"lineage-api-integration"},"Lineage API Integration"),(0,n.yg)("p",null,"The connector uses Google's ",(0,n.yg)("inlineCode",{parentName:"p"},"LineageClient")," to query lineage:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"# Search for upstream lineage (entity is target)\nrequest = SearchLinksRequest(parent=parent, target=entity_reference)\nupstream_links = lineage_client.search_links(request=request)\n\n# Search for downstream lineage (entity is source)\nrequest = SearchLinksRequest(parent=parent, source=entity_reference)\ndownstream_links = lineage_client.search_links(request=request)\n")),(0,n.yg)("h4",{id:"data-structures"},"Data Structures"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"@dataclass\nclass LineageEdge:\n    entity_id: str  # Upstream entity ID\n    audit_stamp: datetime\n    lineage_type: str  # TRANSFORMED, COPY, etc.\n")),(0,n.yg)("h4",{id:"limitations"},"Limitations"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Dataplex does not support column-level lineage extraction"),(0,n.yg)("li",{parentName:"ul"},"Lineage is only available for entities with active lineage tracking"),(0,n.yg)("li",{parentName:"ul"},"Retention period: 30 days (Dataplex limitation)"),(0,n.yg)("li",{parentName:"ul"},"Cross-region lineage is not supported by Dataplex")),(0,n.yg)("h2",{id:"contributing"},"Contributing"),(0,n.yg)("p",null,"When contributing to this connector:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Follow patterns from ",(0,n.yg)("inlineCode",{parentName:"li"},"vertexai")," and ",(0,n.yg)("inlineCode",{parentName:"li"},"bigquery_v2")," sources"),(0,n.yg)("li",{parentName:"ol"},"Add type hints to all functions"),(0,n.yg)("li",{parentName:"ol"},"Update both developer README (this file) and user docs"),(0,n.yg)("li",{parentName:"ol"},"Add unit tests for new functionality"),(0,n.yg)("li",{parentName:"ol"},"Run linting: ",(0,n.yg)("inlineCode",{parentName:"li"},"./gradlew :metadata-ingestion:lintFix")),(0,n.yg)("li",{parentName:"ol"},"Follow the DataHub code standards (see CLAUDE.md in the repo root)")),(0,n.yg)("h2",{id:"references"},"References"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://cloud.google.com/dataplex/docs"},"Dataplex API Documentation")),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://datahubproject.io/docs/developers"},"DataHub Developer Guide"))))}m.isMDXComponent=!0}}]);