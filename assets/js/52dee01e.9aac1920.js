"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[80898],{67510:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>g,contentTitle:()=>p,default:()=>f,frontMatter:()=>d,metadata:()=>m,toc:()=>c});a(96540);var n=a(15680),i=a(53720),l=a(5400);function s(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){return t=null!=t?t:{},Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):function(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))})),e}function o(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}const d={sidebar_position:17,title:"dbt",slug:"/generated/ingestion/sources/dbt",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/dbt.md"},p="dbt",m={unversionedId:"docs/generated/ingestion/sources/dbt",id:"docs/generated/ingestion/sources/dbt",title:"dbt",description:"There are 2 sources that provide integration with dbt",source:"@site/genDocs/docs/generated/ingestion/sources/dbt.md",sourceDirName:"docs/generated/ingestion/sources",slug:"/generated/ingestion/sources/dbt",permalink:"/docs/generated/ingestion/sources/dbt",draft:!1,editUrl:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/dbt.md",tags:[],version:"current",sidebarPosition:17,frontMatter:{sidebar_position:17,title:"dbt",slug:"/generated/ingestion/sources/dbt",custom_edit_url:"https://github.com/datahub-project/datahub/blob/master/docs/generated/ingestion/sources/dbt.md"},sidebar:"overviewSidebar",previous:{title:"Dataplex",permalink:"/docs/generated/ingestion/sources/dataplex"},next:{title:"Delta Lake",permalink:"/docs/generated/ingestion/sources/delta-lake"}},g={},c=[{value:"Concept Mapping",id:"concept-mapping",level:3},{value:"Module <code>dbt</code>",id:"module-dbt",level:2},{value:"Important Capabilities",id:"important-capabilities",level:3},{value:"Setup",id:"setup",level:3},{value:"CLI based Ingestion",id:"cli-based-ingestion",level:3},{value:"Starter Recipe",id:"starter-recipe",level:3},{value:"Config Details",id:"config-details",level:3},{value:"dbt meta automated mappings",id:"dbt-meta-automated-mappings",level:3},{value:"Data Tier - Bronze, Silver, Gold",id:"data-tier---bronze-silver-gold",level:4},{value:"Case Numbers - create tags",id:"case-numbers---create-tags",level:4},{value:"Nested meta properties",id:"nested-meta-properties",level:4},{value:"Stripping out leading @ sign",id:"stripping-out-leading--sign",level:4},{value:"Working with Lists",id:"working-with-lists",level:4},{value:"dbt query_tag automated mappings",id:"dbt-query_tag-automated-mappings",level:3},{value:"Integrating with dbt test",id:"integrating-with-dbt-test",level:3},{value:"View of dbt tests for a dataset",id:"view-of-dbt-tests-for-a-dataset",level:4},{value:"Viewing the SQL for a dbt test",id:"viewing-the-sql-for-a-dbt-test",level:4},{value:"Viewing timeline for a failed dbt test",id:"viewing-timeline-for-a-failed-dbt-test",level:4},{value:"Separating test result emission from other metadata emission",id:"separating-test-result-emission-from-other-metadata-emission",level:4},{value:"Multiple dbt projects",id:"multiple-dbt-projects",level:3},{value:"Reducing &quot;composed of&quot; sprawl by hiding sources",id:"reducing-composed-of-sprawl-by-hiding-sources",level:3},{value:"Semantic Views",id:"semantic-views",level:3},{value:"What are Materialized Semantic Views?",id:"what-are-materialized-semantic-views",level:4},{value:"Configuration",id:"configuration",level:4},{value:"How Semantic Views Appear in DataHub",id:"how-semantic-views-appear-in-datahub",level:4},{value:"Column-Level Lineage for Snowflake Semantic Views",id:"column-level-lineage-for-snowflake-semantic-views",level:4},{value:"Code Coordinates",id:"code-coordinates",level:3},{value:"Module <code>dbt-cloud</code>",id:"module-dbt-cloud",level:2},{value:"Important Capabilities",id:"important-capabilities-1",level:3},{value:"Setup",id:"setup-1",level:3},{value:"Operating Modes",id:"operating-modes",level:4},{value:"1. Explicit Mode (Default)",id:"1-explicit-mode-default",level:5},{value:"2. Auto-Discovery Mode",id:"2-auto-discovery-mode",level:5},{value:"CLI based Ingestion",id:"cli-based-ingestion-1",level:3},{value:"Starter Recipe",id:"starter-recipe-1",level:3},{value:"Config Details",id:"config-details-1",level:3},{value:"Code Coordinates",id:"code-coordinates-1",level:3}],y={toc:c},u="wrapper";function f(e){var{components:t}=e,a=o(e,["components"]);return(0,n.yg)(u,r(function(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{},n=Object.keys(a);"function"==typeof Object.getOwnPropertySymbols&&(n=n.concat(Object.getOwnPropertySymbols(a).filter((function(e){return Object.getOwnPropertyDescriptor(a,e).enumerable})))),n.forEach((function(t){s(e,t,a[t])}))}return e}({},y,a),{components:t,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"dbt"},"dbt"),(0,n.yg)("p",null,"There are 2 sources that provide integration with dbt"),(0,n.yg)("table",null,(0,n.yg)("tr",null,(0,n.yg)("td",null,"Source Module"),(0,n.yg)("td",null,"Documentation")),(0,n.yg)("tr",null,(0,n.yg)("td",null,(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"dbt"))),(0,n.yg)("td",null,(0,n.yg)("p",null," ",(0,n.yg)("a",{parentName:"p",href:"#module-dbt"},"Read more...")))),(0,n.yg)("tr",null,(0,n.yg)("td",null,(0,n.yg)("p",null,(0,n.yg)("inlineCode",{parentName:"p"},"dbt-cloud"))),(0,n.yg)("td",null,(0,n.yg)("p",null," ",(0,n.yg)("a",{parentName:"p",href:"#module-dbt-cloud"},"Read more..."))))),(0,n.yg)("p",null,"Ingesting metadata from dbt requires either using the ",(0,n.yg)("strong",{parentName:"p"},"dbt")," module or the ",(0,n.yg)("strong",{parentName:"p"},"dbt-cloud")," module."),(0,n.yg)("h3",{id:"concept-mapping"},"Concept Mapping"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Source Concept"),(0,n.yg)("th",{parentName:"tr",align:null},"DataHub Concept"),(0,n.yg)("th",{parentName:"tr",align:null},"Notes"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Source"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/dataset"},"Dataset")),(0,n.yg)("td",{parentName:"tr",align:null},"Subtype ",(0,n.yg)("inlineCode",{parentName:"td"},"Source"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Seed"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/dataset"},"Dataset")),(0,n.yg)("td",{parentName:"tr",align:null},"Subtype ",(0,n.yg)("inlineCode",{parentName:"td"},"Seed"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Model"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/dataset"},"Dataset")),(0,n.yg)("td",{parentName:"tr",align:null},"Subtype ",(0,n.yg)("inlineCode",{parentName:"td"},"Model"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Snapshot"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/dataset"},"Dataset")),(0,n.yg)("td",{parentName:"tr",align:null},"Subtype ",(0,n.yg)("inlineCode",{parentName:"td"},"Snapshot"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Semantic View"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/dataset"},"Dataset")),(0,n.yg)("td",{parentName:"tr",align:null},"Subtype ",(0,n.yg)("inlineCode",{parentName:"td"},"Semantic View"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Test"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/assertion"},"Assertion")),(0,n.yg)("td",{parentName:"tr",align:null})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Test Result"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/assertion"},"Assertion Run Result")),(0,n.yg)("td",{parentName:"tr",align:null})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Model Runs"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/generated/metamodel/entities/dataprocessinstance"},"DataProcessInstance")),(0,n.yg)("td",{parentName:"tr",align:null})))),(0,n.yg)("p",null,"Note:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"You must ",(0,n.yg)("strong",{parentName:"li"},"run ingestion for both dbt and your data warehouse")," (target platform). They can be run in any order."),(0,n.yg)("li",{parentName:"ol"},"It generates column lineage between the ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt")," nodes (e.g. when a model/snapshot depends on a dbt source or ephemeral model) as well as lineage between the ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt")," nodes and the underlying target platform nodes (e.g. BigQuery Table -> dbt source, dbt model -> BigQuery table/view)."),(0,n.yg)("li",{parentName:"ol"},'It automatically generates "sibling" relationships between the dbt nodes and the target / data warehouse nodes. These nodes will show up in the UI with both platform logos.'),(0,n.yg)("li",{parentName:"ol"},"We also support automated actions (like add a tag, term or owner) based on properties defined in dbt meta.")),(0,n.yg)("h2",{id:"module-dbt"},"Module ",(0,n.yg)("inlineCode",{parentName:"h2"},"dbt")),(0,n.yg)("p",null,(0,n.yg)("img",{parentName:"p",src:"https://img.shields.io/badge/support%20status-certified-brightgreen",alt:"Certified"})),(0,n.yg)("h3",{id:"important-capabilities"},"Important Capabilities"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Capability"),(0,n.yg)("th",{parentName:"tr",align:null},"Status"),(0,n.yg)("th",{parentName:"tr",align:null},"Notes"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Column-level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default, configure using ",(0,n.yg)("inlineCode",{parentName:"td"},"include_column_lineage"),".")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/stateful#stale-entity-removal"},"Detect Deleted Entities")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default via stateful ingestion.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Table-Level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Test Connection"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")))),(0,n.yg)("h3",{id:"setup"},"Setup"),(0,n.yg)("p",null,"The artifacts used by this source are:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/artifacts/manifest-json"},"dbt manifest file"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"This file contains model, source, tests and lineage data."))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/artifacts/catalog-json"},"dbt catalog file"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"This file contains schema data."),(0,n.yg)("li",{parentName:"ul"},"dbt does not record schema data for Ephemeral models, as such datahub will show Ephemeral models in the lineage, however there will be no associated schema for Ephemeral models"))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/artifacts/sources-json"},"dbt sources file"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"This file contains metadata for sources with freshness checks."),(0,n.yg)("li",{parentName:"ul"},"We transfer dbt's freshness checks to DataHub's last-modified fields."),(0,n.yg)("li",{parentName:"ul"},"Note that this file is optional \u2013 if not specified, we'll use time of ingestion instead as a proxy for time last-modified."))),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/artifacts/run-results-json"},"dbt run_results file"),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"This file contains metadata from the result of a dbt run, e.g. dbt test"),(0,n.yg)("li",{parentName:"ul"},"When provided, we transfer dbt test run results into assertion run events to see a timeline of test runs on the dataset")))),(0,n.yg)("p",null,"To generate these files, we recommend this workflow for dbt build and datahub ingestion."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-sh"},"dbt source snapshot-freshness\ndbt build\ncp target/run_results.json target/run_results_backup.json\ndbt docs generate\ncp target/run_results_backup.json target/run_results.json\n\n# Run datahub ingestion, pointing at the files in the target/ directory\n")),(0,n.yg)("p",null,"The necessary artifact files will then appear in the ",(0,n.yg)("inlineCode",{parentName:"p"},"target/")," directory of your dbt project."),(0,n.yg)("p",null,"We also have guides on handling more complex dbt orchestration techniques and multi-project setups below."),(0,n.yg)("admonition",{title:"Entity is in manifest but missing from catalog",type:"note"},(0,n.yg)("p",{parentName:"admonition"},"This warning usually appears when the catalog.json file was not generated by a ",(0,n.yg)("inlineCode",{parentName:"p"},"dbt docs generate")," command.\nMost other dbt commands generate a partial catalog file, which may impact the completeness of the metadata in ingested into DataHub."),(0,n.yg)("p",{parentName:"admonition"},"Following the above workflow should ensure that the catalog file is generated correctly.")),(0,n.yg)("h3",{id:"cli-based-ingestion"},"CLI based Ingestion"),(0,n.yg)("h3",{id:"starter-recipe"},"Starter Recipe"),(0,n.yg)("p",null,"Check out the following recipe to get started with ingestion! See ",(0,n.yg)("a",{parentName:"p",href:"#config-details"},"below")," for full configuration options."),(0,n.yg)("p",null,"For general pointers on writing and running a recipe, see our ",(0,n.yg)("a",{parentName:"p",href:"/docs/metadata-ingestion#recipes"},"main recipe guide"),"."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: "dbt"\n  config:\n    # Coordinates\n    # To use this as-is, set the environment variable DBT_PROJECT_ROOT to the root folder of your dbt project\n    manifest_path: "${DBT_PROJECT_ROOT}/target/manifest_file.json"\n    catalog_path: "${DBT_PROJECT_ROOT}/target/catalog_file.json"\n    sources_path: "${DBT_PROJECT_ROOT}/target/sources_file.json" # optional for freshness\n    run_results_paths:\n      - "${DBT_PROJECT_ROOT}/target/run_results.json" # optional for recording dbt test results after running dbt test\n\n    # Options\n    target_platform: "my_target_platform_id" # e.g. bigquery/postgres/etc.\n\n# sink configs\n\n')),(0,n.yg)("h3",{id:"config-details"},"Config Details"),(0,n.yg)(i.A,{mdxType:"Tabs"},(0,n.yg)(l.A,{value:"options",label:"Options",default:!0,mdxType:"TabItem"},(0,n.yg)("p",null,"Note that a ",(0,n.yg)("inlineCode",{parentName:"p"},".")," is used to denote nested fields in the YAML recipe."),(0,n.yg)("div",{className:"config-table"},(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:"left"},"Field"),(0,n.yg)("th",{parentName:"tr",align:"left"},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"manifest_path"),"\xa0",(0,n.yg)("abbr",{title:"Required"},"\u2705"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Path to dbt manifest JSON. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.getdbt.com/reference/artifacts/manifest-json"},"https://docs.getdbt.com/reference/artifacts/manifest-json"),". This can be a local file or a URI.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"target_platform"),"\xa0",(0,n.yg)("abbr",{title:"Required"},"\u2705"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The platform that dbt is loading onto. (e.g. bigquery / redshift / postgres etc.)")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"catalog_path"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Path to dbt catalog JSON. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.getdbt.com/reference/artifacts/catalog-json"},"https://docs.getdbt.com/reference/artifacts/catalog-json"),". This file is optional, but highly recommended. Without it, some metadata like column info will be incomplete or missing. This can be a local file or a URI. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"column_meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against dbt column meta properties. Refer to the section below on dbt meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"convert_column_urns_to_lowercase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, converts column URNs to lowercase to ensure cross-platform compatibility. If ",(0,n.yg)("inlineCode",{parentName:"td"},"target_platform")," is Snowflake, the default is True. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"dbt_is_primary_sibling"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Experimental: Controls sibling relationship primary designation between dbt entities and target platform entities. When True (default), dbt entities are primary and target platform entities are secondary. When False, target platform entities are primary and dbt entities are secondary. Uses aspect patches for precise control. Requires DataHub server 1.3.0+. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"drop_duplicate_sources"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, drops sources that have the same name in the target platform as a model. This ensures that lineage is generated reliably, but will lose any documentation associated only with the source. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, applies the mappings that are defined through the meta_mapping directives. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_owner_extraction"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, ownership info will be extracted from the dbt meta ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_query_tag_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, applies the mappings that are defined through the ",(0,n.yg)("inlineCode",{parentName:"td"},"query_tag_mapping")," directives. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_column_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, column-level lineage will be extracted from the dbt node definition. Requires ",(0,n.yg)("inlineCode",{parentName:"td"},"infer_dbt_schemas")," to be enabled. If you run into issues where the column name casing does not match up with properly, providing a datahub_api or using the rest sink will improve accuracy. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_compiled_code"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, includes the compiled code in the emitted metadata. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_database_name"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to add database name to the table urn. Set to False to skip it for engines like AWS Athena where it's not required. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_env_in_assertion_guid"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prior to version 0.9.4.2, the assertion GUIDs did not include the environment. If you're using multiple dbt ingestion that are only distinguished by env, then you should set this flag to True. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"incremental_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, emits incremental/patch lineage for non-dbt entities. When disabled, re-states lineage on each run. This would also require enabling 'incremental",(0,n.yg)("em",{parentName:"td"},"lineage' in the counterpart warehouse ingestion (_e.g.")," BigQuery, Redshift, etc). ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"infer_dbt_schemas"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, schemas will be inferred from the dbt node definition. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against dbt meta properties. Refer to the section below on dbt meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"only_include_if_in_catalog"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"[experimental]"," If true, only include nodes that are also present in the catalog file. This is useful if you only want to include models that have been built by the associated run. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"owner_extraction_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Regex string to extract owner from the dbt node using the ",(0,n.yg)("inlineCode",{parentName:"td"},"(?P<name>...) syntax")," of the ",(0,n.yg)("a",{parentName:"td",href:"https://docs.python.org/3/library/re.html#match-objects"},"match object"),", where the group name must be ",(0,n.yg)("inlineCode",{parentName:"td"},"owner"),". Examples: (1)",(0,n.yg)("inlineCode",{parentName:"td"},'r"(?P<owner>(.*)): (\\w+) (\\w+)"')," will extract ",(0,n.yg)("inlineCode",{parentName:"td"},"jdoe")," as the owner from ",(0,n.yg)("inlineCode",{parentName:"td"},'"jdoe: John Doe"')," (2) ",(0,n.yg)("inlineCode",{parentName:"td"},'r"@(?P<owner>(.*))"')," will extract ",(0,n.yg)("inlineCode",{parentName:"td"},"alice")," as the owner from ",(0,n.yg)("inlineCode",{parentName:"td"},'"@alice"'),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"platform_instance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.datahub.com/docs/platform-instances/"},"https://docs.datahub.com/docs/platform-instances/")," for more details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"prefer_sql_parser_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Normally we use dbt's metadata to generate table lineage. When enabled, we prefer results from the SQL parser when generating lineage instead. This can be useful when dbt models reference tables directly, instead of using the ref() macro. This requires that ",(0,n.yg)("inlineCode",{parentName:"td"},"skip_sources_in_lineage")," is enabled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"query_tag_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against dbt query_tag meta properties. Refer to the section below on dbt meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"skip_sources_in_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"[Experimental]"," When enabled, dbt sources will not be included in the lineage graph. Requires that ",(0,n.yg)("inlineCode",{parentName:"td"},"entities_enabled.sources")," is set to ",(0,n.yg)("inlineCode",{parentName:"td"},"NO"),". This is mainly useful when you have multiple, interdependent dbt projects.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"sources_path"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Path to dbt sources JSON. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.getdbt.com/reference/artifacts/sources-json"},"https://docs.getdbt.com/reference/artifacts/sources-json"),". If not specified, last-modified fields will not be populated. This can be a local file or a URI. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"strip_user_ids_from_email"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether or not to strip email id while adding owners using dbt meta actions. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"tag_prefix"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prefix added to tags during ingestion. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"dbt:")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"target_platform_instance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The platform instance for the platform that dbt is operating on. Use this if you have multiple instances of the same platform (e.g. redshift) and need to distinguish between them. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"test_warnings_are_errors"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, dbt test warnings will be treated as failures. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"use_identifiers"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Use model identifier instead of model name if defined (if not, default to model name). ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"write_semantics"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'Whether the new tags, terms and owners to be added will override the existing ones added only by this source or not. Value for this config can be "PATCH" or "OVERRIDE" ',(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"PATCH")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"env"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Environment to use in namespace when constructing URNs. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"PROD")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"aws_connection"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of AwsConnectionConfig, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When fetching manifest files from s3, configuration for aws connection details ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_access_key_id"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"AWS access key ID. Can be auto-detected, see ",(0,n.yg)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"},"the AWS boto3 docs")," for details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_advanced_config"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Advanced AWS configuration options. These are passed directly to ",(0,n.yg)("a",{parentName:"td",href:"https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html"},"botocore.config.Config"),".")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_endpoint_url"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The AWS service endpoint. This is normally ",(0,n.yg)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html"},"constructed automatically"),", but can be overridden here. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_profile"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The ",(0,n.yg)("a",{parentName:"td",href:"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html"},"named profile")," to use from AWS credentials. Falls back to default profile if not specified and no access keys provided. Profiles are configured in ~/.aws/credentials or ~/.aws/config. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_proxy"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A set of proxy configs to use with AWS. See the ",(0,n.yg)("a",{parentName:"td",href:"https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html"},"botocore.config")," docs for details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_region"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"AWS region code. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_retry_mode"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "legacy", "standard", "adaptive" ',(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"standard")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_retry_num"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Number of times to retry failed AWS requests. See the ",(0,n.yg)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/retries.html"},"botocore.retry")," docs for details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"5")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_secret_access_key"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"AWS secret access key. Can be auto-detected, see ",(0,n.yg)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"},"the AWS boto3 docs")," for details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_session_token"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"AWS session token. Can be auto-detected, see ",(0,n.yg)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"},"the AWS boto3 docs")," for details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"read_timeout"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"number"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The timeout for reading from the connection (in seconds). ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"60")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection."),(0,n.yg)("span",{className:"path-main"},"aws_role"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, array, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"AWS roles to assume. If using the string format, the role ARN can be specified directly. If using the object format, the role can be specified in the RoleArn field and additional available arguments are the same as ",(0,n.yg)("a",{parentName:"td",href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sts.html?highlight=assume_role#STS.Client.assume_role"},"boto3's STS.Client.assume_role"),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection.aws_role."),(0,n.yg)("span",{className:"path-main"},"union"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, AwsAssumeRoleConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection.aws_role.union."),(0,n.yg)("span",{className:"path-main"},"RoleArn"),"\xa0",(0,n.yg)("abbr",{title:"Required if union is set"},"\u2753"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"ARN of the role to assume.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"aws_connection.aws_role.union."),(0,n.yg)("span",{className:"path-main"},"ExternalId"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"External ID to use when assuming the role. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"entities_enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"DBTEntitiesEnabled"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Controls which dbt entities are going to be emitted by this source")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"model_performance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"models"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"seeds"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"snapshots"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"sources"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"test_definitions"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"test_results"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"git_info"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of GitReference, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Reference to your git location to enable easy navigation from DataHub to your dbt files. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"git_info."),(0,n.yg)("span",{className:"path-main"},"repo"),"\xa0",(0,n.yg)("abbr",{title:"Required if git_info is set"},"\u2753"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Name of your Git repo e.g. ",(0,n.yg)("a",{parentName:"td",href:"https://github.com/datahub-project/datahub"},"https://github.com/datahub-project/datahub")," or ",(0,n.yg)("a",{parentName:"td",href:"https://gitlab.com/gitlab-org/gitlab"},"https://gitlab.com/gitlab-org/gitlab"),". If organization/repo is provided, we assume it is a GitHub repo.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"git_info."),(0,n.yg)("span",{className:"path-main"},"branch"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Branch on which your files live by default. Typically main or master. This can also be a commit hash. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"main")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"git_info."),(0,n.yg)("span",{className:"path-main"},"url_subdir"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prefix to prepend when generating URLs for files - useful when files are in a subdirectory. Only affects URL generation, not git operations. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"git_info."),(0,n.yg)("span",{className:"path-main"},"url_template"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Template for generating a URL to a file in the repo e.g. '{repo_url}/blob/{branch}/{file_path}'. We can infer this for GitHub and GitLab repos, and it is otherwise required.It supports the following variables: {repo_url}, {branch}, {file_path} ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"materialized_node_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"MaterializedNodePatternConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Configuration for filtering materialized nodes based on their physical location")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern."),(0,n.yg)("span",{className:"path-main"},"database_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern.database_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern."),(0,n.yg)("span",{className:"path-main"},"schema_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern.schema_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern."),(0,n.yg)("span",{className:"path-main"},"table_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern.table_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"node_name_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"node_name_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"run_results_paths"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"array"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Path to output of dbt test run as run_results files in JSON format. If not specified, test execution results and model performance metadata will not be populated in DataHub.If invoking dbt multiple times, you can provide paths to multiple run result files. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.getdbt.com/reference/artifacts/run-results-json"},"https://docs.getdbt.com/reference/artifacts/run-results-json"),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"[","]")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"run_results_paths."),(0,n.yg)("span",{className:"path-main"},"string"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"})),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"stateful_ingestion"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of StatefulStaleMetadataRemovalConfig, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"DBT Stateful Ingestion Config. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or ",(0,n.yg)("inlineCode",{parentName:"td"},"datahub_api")," is specified, otherwise False ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"fail_safe_threshold"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"number"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the 'fail_safe_threshold'. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"75.0")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"remove_stale_metadata"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))))))),(0,n.yg)(l.A,{value:"schema",label:"Schema",mdxType:"TabItem"},(0,n.yg)("p",null,"The ",(0,n.yg)("a",{parentName:"p",href:"https://json-schema.org/"},"JSONSchema")," for this configuration is inlined below."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "$defs": {\n    "AllowDenyPattern": {\n      "additionalProperties": false,\n      "description": "A class to store allow deny regexes",\n      "properties": {\n        "allow": {\n          "default": [\n            ".*"\n          ],\n          "description": "List of regex patterns to include in ingestion",\n          "items": {\n            "type": "string"\n          },\n          "title": "Allow",\n          "type": "array"\n        },\n        "deny": {\n          "default": [],\n          "description": "List of regex patterns to exclude from ingestion.",\n          "items": {\n            "type": "string"\n          },\n          "title": "Deny",\n          "type": "array"\n        },\n        "ignoreCase": {\n          "anyOf": [\n            {\n              "type": "boolean"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": true,\n          "description": "Whether to ignore case sensitivity during pattern matching.",\n          "title": "Ignorecase"\n        }\n      },\n      "title": "AllowDenyPattern",\n      "type": "object"\n    },\n    "AwsAssumeRoleConfig": {\n      "additionalProperties": true,\n      "properties": {\n        "RoleArn": {\n          "description": "ARN of the role to assume.",\n          "title": "Rolearn",\n          "type": "string"\n        },\n        "ExternalId": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "External ID to use when assuming the role.",\n          "title": "Externalid"\n        }\n      },\n      "required": [\n        "RoleArn"\n      ],\n      "title": "AwsAssumeRoleConfig",\n      "type": "object"\n    },\n    "AwsConnectionConfig": {\n      "additionalProperties": false,\n      "description": "Common AWS credentials config.\\n\\nCurrently used by:\\n    - Glue source\\n    - SageMaker source\\n    - dbt source",\n      "properties": {\n        "aws_access_key_id": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "AWS access key ID. Can be auto-detected, see [the AWS boto3 docs](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) for details.",\n          "title": "Aws Access Key Id"\n        },\n        "aws_secret_access_key": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "AWS secret access key. Can be auto-detected, see [the AWS boto3 docs](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) for details.",\n          "title": "Aws Secret Access Key"\n        },\n        "aws_session_token": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "AWS session token. Can be auto-detected, see [the AWS boto3 docs](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html) for details.",\n          "title": "Aws Session Token"\n        },\n        "aws_role": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "items": {\n                "anyOf": [\n                  {\n                    "type": "string"\n                  },\n                  {\n                    "$ref": "#/$defs/AwsAssumeRoleConfig"\n                  }\n                ]\n              },\n              "type": "array"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "AWS roles to assume. If using the string format, the role ARN can be specified directly. If using the object format, the role can be specified in the RoleArn field and additional available arguments are the same as [boto3\'s STS.Client.assume_role](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sts.html?highlight=assume_role#STS.Client.assume_role).",\n          "title": "Aws Role"\n        },\n        "aws_profile": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "The [named profile](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html) to use from AWS credentials. Falls back to default profile if not specified and no access keys provided. Profiles are configured in ~/.aws/credentials or ~/.aws/config.",\n          "title": "Aws Profile"\n        },\n        "aws_region": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "AWS region code.",\n          "title": "Aws Region"\n        },\n        "aws_endpoint_url": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "The AWS service endpoint. This is normally [constructed automatically](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html), but can be overridden here.",\n          "title": "Aws Endpoint Url"\n        },\n        "aws_proxy": {\n          "anyOf": [\n            {\n              "additionalProperties": {\n                "type": "string"\n              },\n              "type": "object"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "A set of proxy configs to use with AWS. See the [botocore.config](https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html) docs for details.",\n          "title": "Aws Proxy"\n        },\n        "aws_retry_num": {\n          "default": 5,\n          "description": "Number of times to retry failed AWS requests. See the [botocore.retry](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/retries.html) docs for details.",\n          "title": "Aws Retry Num",\n          "type": "integer"\n        },\n        "aws_retry_mode": {\n          "default": "standard",\n          "description": "Retry mode to use for failed AWS requests. See the [botocore.retry](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/retries.html) docs for details.",\n          "enum": [\n            "legacy",\n            "standard",\n            "adaptive"\n          ],\n          "title": "Aws Retry Mode",\n          "type": "string"\n        },\n        "read_timeout": {\n          "default": 60,\n          "description": "The timeout for reading from the connection (in seconds).",\n          "title": "Read Timeout",\n          "type": "number"\n        },\n        "aws_advanced_config": {\n          "additionalProperties": true,\n          "description": "Advanced AWS configuration options. These are passed directly to [botocore.config.Config](https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html).",\n          "title": "Aws Advanced Config",\n          "type": "object"\n        }\n      },\n      "title": "AwsConnectionConfig",\n      "type": "object"\n    },\n    "DBTEntitiesEnabled": {\n      "additionalProperties": false,\n      "description": "Controls which dbt entities are going to be emitted by this source",\n      "properties": {\n        "models": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt models when set to Yes or Only"\n        },\n        "sources": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt sources when set to Yes or Only"\n        },\n        "seeds": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt seeds when set to Yes or Only"\n        },\n        "snapshots": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt snapshots when set to Yes or Only"\n        },\n        "test_definitions": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for test definitions when enabled when set to Yes or Only"\n        },\n        "test_results": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for test results when set to Yes or Only"\n        },\n        "model_performance": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit model performance metadata when set to Yes or Only. Only supported with dbt core."\n        }\n      },\n      "title": "DBTEntitiesEnabled",\n      "type": "object"\n    },\n    "EmitDirective": {\n      "description": "A holder for directives for emission for specific types of entities",\n      "enum": [\n        "YES",\n        "NO",\n        "ONLY"\n      ],\n      "title": "EmitDirective",\n      "type": "string"\n    },\n    "GitReference": {\n      "additionalProperties": false,\n      "description": "Reference to a hosted Git repository. Used to generate \\"view source\\" links.",\n      "properties": {\n        "repo": {\n          "description": "Name of your Git repo e.g. https://github.com/datahub-project/datahub or https://gitlab.com/gitlab-org/gitlab. If organization/repo is provided, we assume it is a GitHub repo.",\n          "title": "Repo",\n          "type": "string"\n        },\n        "branch": {\n          "default": "main",\n          "description": "Branch on which your files live by default. Typically main or master. This can also be a commit hash.",\n          "title": "Branch",\n          "type": "string"\n        },\n        "url_subdir": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Prefix to prepend when generating URLs for files - useful when files are in a subdirectory. Only affects URL generation, not git operations.",\n          "title": "Url Subdir"\n        },\n        "url_template": {\n          "anyOf": [\n            {\n              "type": "string"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": null,\n          "description": "Template for generating a URL to a file in the repo e.g. \'{repo_url}/blob/{branch}/{file_path}\'. We can infer this for GitHub and GitLab repos, and it is otherwise required.It supports the following variables: {repo_url}, {branch}, {file_path}",\n          "title": "Url Template"\n        }\n      },\n      "required": [\n        "repo"\n      ],\n      "title": "GitReference",\n      "type": "object"\n    },\n    "MaterializedNodePatternConfig": {\n      "additionalProperties": false,\n      "description": "Configuration for filtering materialized nodes based on their physical location",\n      "properties": {\n        "database_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns for database names to filter materialized nodes."\n        },\n        "schema_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns for schema names in format \'{database}.{schema}\' to filter materialized nodes."\n        },\n        "table_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns for table/view names in format \'{database}.{schema}.{table}\' to filter materialized nodes."\n        }\n      },\n      "title": "MaterializedNodePatternConfig",\n      "type": "object"\n    },\n    "StatefulStaleMetadataRemovalConfig": {\n      "additionalProperties": false,\n      "description": "Base specialized config for Stateful Ingestion with stale metadata removal capability.",\n      "properties": {\n        "enabled": {\n          "default": false,\n          "description": "Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or `datahub_api` is specified, otherwise False",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "remove_stale_metadata": {\n          "default": true,\n          "description": "Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled.",\n          "title": "Remove Stale Metadata",\n          "type": "boolean"\n        },\n        "fail_safe_threshold": {\n          "default": 75.0,\n          "description": "Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the \'fail_safe_threshold\'.",\n          "maximum": 100.0,\n          "minimum": 0.0,\n          "title": "Fail Safe Threshold",\n          "type": "number"\n        }\n      },\n      "title": "StatefulStaleMetadataRemovalConfig",\n      "type": "object"\n    }\n  },\n  "additionalProperties": false,\n  "properties": {\n    "incremental_lineage": {\n      "default": true,\n      "description": "When enabled, emits incremental/patch lineage for non-dbt entities. When disabled, re-states lineage on each run. This would also require enabling \'incremental_lineage\' in the counterpart warehouse ingestion (_e.g._ BigQuery, Redshift, etc).",\n      "title": "Incremental Lineage",\n      "type": "boolean"\n    },\n    "env": {\n      "default": "PROD",\n      "description": "Environment to use in namespace when constructing URNs.",\n      "title": "Env",\n      "type": "string"\n    },\n    "platform_instance": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See https://docs.datahub.com/docs/platform-instances/ for more details.",\n      "title": "Platform Instance"\n    },\n    "stateful_ingestion": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/StatefulStaleMetadataRemovalConfig"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "DBT Stateful Ingestion Config."\n    },\n    "target_platform": {\n      "description": "The platform that dbt is loading onto. (e.g. bigquery / redshift / postgres etc.)",\n      "title": "Target Platform",\n      "type": "string"\n    },\n    "target_platform_instance": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The platform instance for the platform that dbt is operating on. Use this if you have multiple instances of the same platform (e.g. redshift) and need to distinguish between them.",\n      "title": "Target Platform Instance"\n    },\n    "use_identifiers": {\n      "default": false,\n      "description": "Use model identifier instead of model name if defined (if not, default to model name).",\n      "title": "Use Identifiers",\n      "type": "boolean"\n    },\n    "entities_enabled": {\n      "$ref": "#/$defs/DBTEntitiesEnabled",\n      "default": {\n        "models": "YES",\n        "sources": "YES",\n        "seeds": "YES",\n        "snapshots": "YES",\n        "test_definitions": "YES",\n        "test_results": "YES",\n        "model_performance": "YES"\n      },\n      "description": "Controls for enabling / disabling metadata emission for different dbt entities (models, test definitions, test results, etc.)"\n    },\n    "prefer_sql_parser_lineage": {\n      "default": false,\n      "description": "Normally we use dbt\'s metadata to generate table lineage. When enabled, we prefer results from the SQL parser when generating lineage instead. This can be useful when dbt models reference tables directly, instead of using the ref() macro. This requires that `skip_sources_in_lineage` is enabled.",\n      "title": "Prefer Sql Parser Lineage",\n      "type": "boolean"\n    },\n    "skip_sources_in_lineage": {\n      "default": false,\n      "description": "[Experimental] When enabled, dbt sources will not be included in the lineage graph. Requires that `entities_enabled.sources` is set to `NO`. This is mainly useful when you have multiple, interdependent dbt projects. ",\n      "title": "Skip Sources In Lineage",\n      "type": "boolean"\n    },\n    "tag_prefix": {\n      "default": "dbt:",\n      "description": "Prefix added to tags during ingestion.",\n      "title": "Tag Prefix",\n      "type": "string"\n    },\n    "node_name_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "regex patterns for dbt model names to filter in ingestion."\n    },\n    "materialized_node_pattern": {\n      "$ref": "#/$defs/MaterializedNodePatternConfig",\n      "default": {\n        "database_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        },\n        "schema_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        },\n        "table_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        }\n      },\n      "description": "Advanced filtering for materialized nodes based on their physical database location. Provides fine-grained control over database.schema.table patterns for catalog consistency."\n    },\n    "meta_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against dbt meta properties. Refer to the section below on dbt meta automated mappings.",\n      "title": "Meta Mapping",\n      "type": "object"\n    },\n    "column_meta_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against dbt column meta properties. Refer to the section below on dbt meta automated mappings.",\n      "title": "Column Meta Mapping",\n      "type": "object"\n    },\n    "enable_meta_mapping": {\n      "default": true,\n      "description": "When enabled, applies the mappings that are defined through the meta_mapping directives.",\n      "title": "Enable Meta Mapping",\n      "type": "boolean"\n    },\n    "query_tag_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against dbt query_tag meta properties. Refer to the section below on dbt meta automated mappings.",\n      "title": "Query Tag Mapping",\n      "type": "object"\n    },\n    "enable_query_tag_mapping": {\n      "default": true,\n      "description": "When enabled, applies the mappings that are defined through the `query_tag_mapping` directives.",\n      "title": "Enable Query Tag Mapping",\n      "type": "boolean"\n    },\n    "write_semantics": {\n      "default": "PATCH",\n      "description": "Whether the new tags, terms and owners to be added will override the existing ones added only by this source or not. Value for this config can be \\"PATCH\\" or \\"OVERRIDE\\"",\n      "title": "Write Semantics",\n      "type": "string"\n    },\n    "strip_user_ids_from_email": {\n      "default": false,\n      "description": "Whether or not to strip email id while adding owners using dbt meta actions.",\n      "title": "Strip User Ids From Email",\n      "type": "boolean"\n    },\n    "enable_owner_extraction": {\n      "default": true,\n      "description": "When enabled, ownership info will be extracted from the dbt meta",\n      "title": "Enable Owner Extraction",\n      "type": "boolean"\n    },\n    "owner_extraction_pattern": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Regex string to extract owner from the dbt node using the `(?P<name>...) syntax` of the [match object](https://docs.python.org/3/library/re.html#match-objects), where the group name must be `owner`. Examples: (1)`r\\"(?P<owner>(.*)): (\\\\w+) (\\\\w+)\\"` will extract `jdoe` as the owner from `\\"jdoe: John Doe\\"` (2) `r\\"@(?P<owner>(.*))\\"` will extract `alice` as the owner from `\\"@alice\\"`.",\n      "title": "Owner Extraction Pattern"\n    },\n    "include_env_in_assertion_guid": {\n      "default": false,\n      "description": "Prior to version 0.9.4.2, the assertion GUIDs did not include the environment. If you\'re using multiple dbt ingestion that are only distinguished by env, then you should set this flag to True.",\n      "title": "Include Env In Assertion Guid",\n      "type": "boolean"\n    },\n    "convert_column_urns_to_lowercase": {\n      "default": false,\n      "description": "When enabled, converts column URNs to lowercase to ensure cross-platform compatibility. If `target_platform` is Snowflake, the default is True.",\n      "title": "Convert Column Urns To Lowercase",\n      "type": "boolean"\n    },\n    "test_warnings_are_errors": {\n      "default": false,\n      "description": "When enabled, dbt test warnings will be treated as failures.",\n      "title": "Test Warnings Are Errors",\n      "type": "boolean"\n    },\n    "infer_dbt_schemas": {\n      "default": true,\n      "description": "When enabled, schemas will be inferred from the dbt node definition.",\n      "title": "Infer Dbt Schemas",\n      "type": "boolean"\n    },\n    "include_column_lineage": {\n      "default": true,\n      "description": "When enabled, column-level lineage will be extracted from the dbt node definition. Requires `infer_dbt_schemas` to be enabled. If you run into issues where the column name casing does not match up with properly, providing a datahub_api or using the rest sink will improve accuracy.",\n      "title": "Include Column Lineage",\n      "type": "boolean"\n    },\n    "include_compiled_code": {\n      "default": true,\n      "description": "When enabled, includes the compiled code in the emitted metadata.",\n      "title": "Include Compiled Code",\n      "type": "boolean"\n    },\n    "include_database_name": {\n      "default": true,\n      "description": "Whether to add database name to the table urn. Set to False to skip it for engines like AWS Athena where it\'s not required.",\n      "title": "Include Database Name",\n      "type": "boolean"\n    },\n    "dbt_is_primary_sibling": {\n      "default": true,\n      "description": "Experimental: Controls sibling relationship primary designation between dbt entities and target platform entities. When True (default), dbt entities are primary and target platform entities are secondary. When False, target platform entities are primary and dbt entities are secondary. Uses aspect patches for precise control. Requires DataHub server 1.3.0+.",\n      "title": "Dbt Is Primary Sibling",\n      "type": "boolean"\n    },\n    "drop_duplicate_sources": {\n      "default": true,\n      "description": "When enabled, drops sources that have the same name in the target platform as a model. This ensures that lineage is generated reliably, but will lose any documentation associated only with the source.",\n      "title": "Drop Duplicate Sources",\n      "type": "boolean"\n    },\n    "manifest_path": {\n      "description": "Path to dbt manifest JSON. See https://docs.getdbt.com/reference/artifacts/manifest-json. This can be a local file or a URI.",\n      "title": "Manifest Path",\n      "type": "string"\n    },\n    "catalog_path": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Path to dbt catalog JSON. See https://docs.getdbt.com/reference/artifacts/catalog-json. This file is optional, but highly recommended. Without it, some metadata like column info will be incomplete or missing. This can be a local file or a URI.",\n      "title": "Catalog Path"\n    },\n    "sources_path": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Path to dbt sources JSON. See https://docs.getdbt.com/reference/artifacts/sources-json. If not specified, last-modified fields will not be populated. This can be a local file or a URI.",\n      "title": "Sources Path"\n    },\n    "run_results_paths": {\n      "default": [],\n      "description": "Path to output of dbt test run as run_results files in JSON format. If not specified, test execution results and model performance metadata will not be populated in DataHub.If invoking dbt multiple times, you can provide paths to multiple run result files. See https://docs.getdbt.com/reference/artifacts/run-results-json.",\n      "items": {\n        "type": "string"\n      },\n      "title": "Run Results Paths",\n      "type": "array"\n    },\n    "only_include_if_in_catalog": {\n      "default": false,\n      "description": "[experimental] If true, only include nodes that are also present in the catalog file. This is useful if you only want to include models that have been built by the associated run.",\n      "title": "Only Include If In Catalog",\n      "type": "boolean"\n    },\n    "aws_connection": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/AwsConnectionConfig"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "When fetching manifest files from s3, configuration for aws connection details"\n    },\n    "git_info": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/GitReference"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Reference to your git location to enable easy navigation from DataHub to your dbt files."\n    }\n  },\n  "required": [\n    "target_platform",\n    "manifest_path"\n  ],\n  "title": "DBTCoreConfig",\n  "type": "object"\n}\n')))),(0,n.yg)("h3",{id:"dbt-meta-automated-mappings"},"dbt meta automated mappings"),(0,n.yg)("p",null,"dbt allows authors to define meta properties for datasets. Checkout this link to know more - ",(0,n.yg)("a",{parentName:"p",href:"https://docs.getdbt.com/reference/resource-configs/meta"},"dbt meta"),". Our dbt source allows users to define\nactions such as add a tag, term or owner. For example if a dbt model has a meta config ",(0,n.yg)("inlineCode",{parentName:"p"},'"has_pii": True'),", we can define an action\nthat evaluates if the property is set to true and add, lets say, a ",(0,n.yg)("inlineCode",{parentName:"p"},"pii")," tag.\nTo leverage this feature we require users to define mappings as part of the recipe. The following section describes how you can build these mappings. Listed below is a ",(0,n.yg)("inlineCode",{parentName:"p"},"meta_mapping")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"column_meta_mapping")," section that among other things, looks for keys like ",(0,n.yg)("inlineCode",{parentName:"p"},"business_owner")," and adds owners that are listed there."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta_mapping:\n  business_owner:\n    match: ".*"\n    operation: "add_owner"\n    config:\n      owner_type: user\n      owner_category: BUSINESS_OWNER\n  has_pii:\n    match: True\n    operation: "add_tag"\n    config:\n      tag: "has_pii_test"\n  int_property:\n    match: 1\n    operation: "add_tag"\n    config:\n      tag: "int_meta_property"\n  double_property:\n    match: 2.5\n    operation: "add_term"\n    config:\n      term: "double_meta_property"\n  data_governance.team_owner:\n    match: "Finance"\n    operation: "add_term"\n    config:\n      term: "Finance_test"\n  terms_list:\n    match: ".*"\n    operation: "add_terms"\n    config:\n      separator: ","\n  documentation_link:\n    match: "(?:https?)?\\:\\/\\/\\w*[^#]*"\n    operation: "add_doc_link"\n    config:\n      link: {{ $match }}\n      description: "Documentation Link"\ncolumn_meta_mapping:\n  terms_list:\n    match: ".*"\n    operation: "add_terms"\n    config:\n      separator: ","\n  is_sensitive:\n    match: True\n    operation: "add_tag"\n    config:\n      tag: "sensitive"\n  gdpr.pii:\n    match: true\n    operation: "add_tag"\n    config:\n      tag: "pii"\n')),(0,n.yg)("p",null,"We support the following operations:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"add_tag - Requires ",(0,n.yg)("inlineCode",{parentName:"p"},"tag")," property in config.")),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"add_term - Requires ",(0,n.yg)("inlineCode",{parentName:"p"},"term")," property in config.")),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"add_terms - Accepts an optional ",(0,n.yg)("inlineCode",{parentName:"p"},"separator")," property in config.")),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"add_owner - Requires ",(0,n.yg)("inlineCode",{parentName:"p"},"owner_type")," property in config which can be either ",(0,n.yg)("inlineCode",{parentName:"p"},"user")," or ",(0,n.yg)("inlineCode",{parentName:"p"},"group"),". Optionally accepts the ",(0,n.yg)("inlineCode",{parentName:"p"},"owner_category")," config property which can be set to either a ",(0,n.yg)("a",{parentName:"p",href:"/docs/ownership/ownership-types"},"custom ownership type")," urn like ",(0,n.yg)("inlineCode",{parentName:"p"},"urn:li:ownershipType:architect")," or one of ",(0,n.yg)("inlineCode",{parentName:"p"},"['TECHNICAL_OWNER', 'BUSINESS_OWNER', 'DATA_STEWARD', 'DATAOWNER'")," (defaults to ",(0,n.yg)("inlineCode",{parentName:"p"},"DATAOWNER"),")."),(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"The ",(0,n.yg)("inlineCode",{parentName:"li"},"owner_type")," property will be ignored if the owner is a fully qualified urn."),(0,n.yg)("li",{parentName:"ul"},"You can use commas to specify multiple owners - e.g. ",(0,n.yg)("inlineCode",{parentName:"li"},'business_owner: "jane,john,urn:li:corpGroup:data-team"'),"."))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("p",{parentName:"li"},"add_doc_link - Requires ",(0,n.yg)("inlineCode",{parentName:"p"},"link")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"description")," properties in config. Upon ingestion run, this will overwrite current links in the institutional knowledge section with this new link. The anchor text is defined here in the meta_mappings as ",(0,n.yg)("inlineCode",{parentName:"p"},"description"),"."))),(0,n.yg)("p",null,"Note:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"The dbt ",(0,n.yg)("inlineCode",{parentName:"li"},"meta_mapping")," config works at the model level, while the ",(0,n.yg)("inlineCode",{parentName:"li"},"column_meta_mapping")," config works at the column level. The ",(0,n.yg)("inlineCode",{parentName:"li"},"add_owner")," operation is not supported at the column level."),(0,n.yg)("li",{parentName:"ol"},"For string meta properties we support regex matching."),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"List support"),": YAML lists are now supported in meta properties. Each item in the list that matches the regex pattern will be processed.")),(0,n.yg)("p",null,"With regex matching, you can also use the matched value to customize how you populate the tag, term or owner fields. Here are a few advanced examples:"),(0,n.yg)("h4",{id:"data-tier---bronze-silver-gold"},"Data Tier - Bronze, Silver, Gold"),(0,n.yg)("p",null,"If your meta section looks like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"meta:\n  data_tier: Bronze # chosen from [Bronze,Gold,Silver]\n")),(0,n.yg)("p",null,"and you wanted to attach a glossary term like ",(0,n.yg)("inlineCode",{parentName:"p"},"urn:li:glossaryTerm:Bronze")," for all the models that have this value in the meta section attached to them, the following meta_mapping section would achieve that outcome:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta_mapping:\n  data_tier:\n    match: "Bronze|Silver|Gold"\n    operation: "add_term"\n    config:\n      term: "{{ $match }}"\n')),(0,n.yg)("p",null,"to match any data_tier of Bronze, Silver or Gold and maps it to a glossary term with the same name."),(0,n.yg)("h4",{id:"case-numbers---create-tags"},"Case Numbers - create tags"),(0,n.yg)("p",null,"If your meta section looks like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"meta:\n  case: PLT-4678 # internal Case Number\n")),(0,n.yg)("p",null,"and you want to generate tags that look like ",(0,n.yg)("inlineCode",{parentName:"p"},"case_4678")," from this, you can use the following meta_mapping section:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta_mapping:\n  case:\n    match: "PLT-(.*)"\n    operation: "add_tag"\n     config:\n       tag: "case_{{ $match }}"\n')),(0,n.yg)("h4",{id:"nested-meta-properties"},"Nested meta properties"),(0,n.yg)("p",null,"If your meta section has nested properties and looks like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta:\n  data_governance:\n    team_owner: "Finance"\n')),(0,n.yg)("p",null,"and you want attach term Finance_test in case of data_governance.team_owner is set to Finance, you can use the following meta_mapping section:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta_mapping:\n  data_governance.team_owner:\n    match: "Finance"\n    operation: "add_term"\n    config:\n      term: "Finance_test"\n')),(0,n.yg)("p",null,"Note: nested meta properties mapping is supported also for column_meta_mapping"),(0,n.yg)("h4",{id:"stripping-out-leading--sign"},"Stripping out leading @ sign"),(0,n.yg)("p",null,"You can also match specific groups within the value to extract subsets of the matched value. e.g. if you have a meta section that looks like this:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta:\n  owner: "@finance-team"\n  business_owner: "@janet"\n')),(0,n.yg)("p",null,"and you want to mark the finance-team as a group that owns the dataset (skipping the leading @ sign), while marking janet as an individual user (again, skipping the leading @ sign) that owns the dataset, you can use the following meta-mapping section."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta_mapping:\n  owner:\n    match: "^@(.*)"\n    operation: "add_owner"\n    config:\n      owner_type: group\n  business_owner:\n    match: "^@(?P<owner>(.*))"\n    operation: "add_owner"\n    config:\n      owner_type: user\n      owner_category: BUSINESS_OWNER\n')),(0,n.yg)("p",null,"In the examples above, we show two ways of writing the matching regexes. In the first one, ",(0,n.yg)("inlineCode",{parentName:"p"},"^@(.*)")," the first matching group (a.k.a. match.group(1)) is automatically inferred. In the second example, ",(0,n.yg)("inlineCode",{parentName:"p"},"^@(?P<owner>(.*))"),", we use a named matching group (called owner, since we are matching an owner) to capture the string we want to provide to the ownership urn."),(0,n.yg)("h4",{id:"working-with-lists"},"Working with Lists"),(0,n.yg)("p",null,"YAML lists are fully supported in dbt meta properties. Each item in the list is evaluated against the match pattern, and only matching items are processed."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"meta:\n  owners:\n    - alice@company.com\n    - bob@company.com\n    - contractor@external.com\n")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'meta_mapping:\n  owners:\n    match: ".*@company.com"\n    operation: "add_owner"\n    config:\n      owner_type: user\n')),(0,n.yg)("p",null,"This will add ",(0,n.yg)("inlineCode",{parentName:"p"},"alice@company.com")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"bob@company.com")," as owners (matching ",(0,n.yg)("inlineCode",{parentName:"p"},".*@company.com"),") but skip ",(0,n.yg)("inlineCode",{parentName:"p"},"contractor@external.com")," (doesn't match the pattern)."),(0,n.yg)("h3",{id:"dbt-query_tag-automated-mappings"},"dbt query_tag automated mappings"),(0,n.yg)("p",null,"This works similarly as the dbt meta mapping but for the query tags"),(0,n.yg)("p",null,"We support the below actions -"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"add_tag - Requires ",(0,n.yg)("inlineCode",{parentName:"li"},"tag")," property in config.")),(0,n.yg)("p",null,"The below example set as global tag the query tag ",(0,n.yg)("inlineCode",{parentName:"p"},"tag")," key's value."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-json"},'"query_tag_mapping":\n{\n   "tag":\n      "match": ".*"\n      "operation": "add_tag"\n      "config":\n        "tag": "{{ $match }}"\n}\n')),(0,n.yg)("h3",{id:"integrating-with-dbt-test"},"Integrating with dbt test"),(0,n.yg)("p",null,"To integrate with dbt tests, the ",(0,n.yg)("inlineCode",{parentName:"p"},"dbt")," source needs access to the ",(0,n.yg)("inlineCode",{parentName:"p"},"run_results.json")," file generated after a ",(0,n.yg)("inlineCode",{parentName:"p"},"dbt test")," or ",(0,n.yg)("inlineCode",{parentName:"p"},"dbt build")," execution. Typically, this is written to the ",(0,n.yg)("inlineCode",{parentName:"p"},"target")," directory. A common pattern you can follow is:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Run ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt build")),(0,n.yg)("li",{parentName:"ol"},"Copy the ",(0,n.yg)("inlineCode",{parentName:"li"},"target/run_results.json")," file to a separate location. This is important, because otherwise subsequent ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt")," commands will overwrite the run results."),(0,n.yg)("li",{parentName:"ol"},"Run ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt docs generate")," to generate the ",(0,n.yg)("inlineCode",{parentName:"li"},"manifest.json")," and ",(0,n.yg)("inlineCode",{parentName:"li"},"catalog.json")," files"),(0,n.yg)("li",{parentName:"ol"},"The dbt source makes use of the manifest, catalog, and run results file, and hence will need to be moved to a location accessible to the ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt")," source (e.g. s3 or local file system). In the ingestion recipe, the ",(0,n.yg)("inlineCode",{parentName:"li"},"run_results_paths")," config must be set to the location of the ",(0,n.yg)("inlineCode",{parentName:"li"},"run_results.json")," file from the ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt build")," or ",(0,n.yg)("inlineCode",{parentName:"li"},"dbt test")," run.")),(0,n.yg)("p",null,"The connector will produce the following things:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Assertion definitions that are attached to the dataset (or datasets)"),(0,n.yg)("li",{parentName:"ul"},"Results from running the tests attached to the timeline of the dataset")),(0,n.yg)("admonition",{title:"Missing test results?",type:"note"},(0,n.yg)("p",{parentName:"admonition"},"The most common reason for missing test results is that the ",(0,n.yg)("inlineCode",{parentName:"p"},"run_results.json")," with the test result information is getting overwritten by a subsequent ",(0,n.yg)("inlineCode",{parentName:"p"},"dbt")," command. We recommend copying the ",(0,n.yg)("inlineCode",{parentName:"p"},"run_results.json")," file before running other ",(0,n.yg)("inlineCode",{parentName:"p"},"dbt")," commands."),(0,n.yg)("pre",{parentName:"admonition"},(0,n.yg)("code",{parentName:"pre",className:"language-sh"},"dbt source snapshot-freshness\ndbt build\ncp target/run_results.json target/run_results_backup.json\ndbt docs generate\ncp target/run_results_backup.json target/run_results.json\n"))),(0,n.yg)("h4",{id:"view-of-dbt-tests-for-a-dataset"},"View of dbt tests for a dataset"),(0,n.yg)("p",null,(0,n.yg)("img",{parentName:"p",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/dbt-tests-view.png",alt:"test view"})),(0,n.yg)("h4",{id:"viewing-the-sql-for-a-dbt-test"},"Viewing the SQL for a dbt test"),(0,n.yg)("p",null,(0,n.yg)("img",{parentName:"p",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/dbt-test-logic-view.png",alt:"test logic view"})),(0,n.yg)("h4",{id:"viewing-timeline-for-a-failed-dbt-test"},"Viewing timeline for a failed dbt test"),(0,n.yg)("p",null,(0,n.yg)("img",{parentName:"p",src:"https://raw.githubusercontent.com/datahub-project/static-assets/main/imgs/dbt-tests-failure-view.png",alt:"test view"})),(0,n.yg)("h4",{id:"separating-test-result-emission-from-other-metadata-emission"},"Separating test result emission from other metadata emission"),(0,n.yg)("p",null,"You can segregate emission of test results from the emission of other dbt metadata using the ",(0,n.yg)("inlineCode",{parentName:"p"},"entities_enabled")," config flag.\nThe following recipe shows you how to emit only test results."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"source:\n  type: dbt\n  config:\n    manifest_path: _path_to_manifest_json\n    catalog_path: _path_to_catalog_json\n    run_results_paths:\n      - _path_to_run_results_json\n    target_platform: postgres\n    entities_enabled:\n      test_results: Only\n")),(0,n.yg)("p",null,"Similarly, the following recipe shows you how to emit everything (i.e. models, sources, seeds, test definitions) but not test results:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"source:\n  type: dbt\n  config:\n    manifest_path: _path_to_manifest_json\n    catalog_path: _path_to_catalog_json\n    run_results_paths:\n      - _path_to_run_results_json\n    target_platform: postgres\n    entities_enabled:\n      test_results: No\n")),(0,n.yg)("h3",{id:"multiple-dbt-projects"},"Multiple dbt projects"),(0,n.yg)("p",null,"In more complex dbt setups, you may have multiple dbt projects, where models from one project are used as sources in another project.\nDataHub supports this setup natively."),(0,n.yg)("p",null,"Each dbt project should have its own dbt ingestion recipe, and the ",(0,n.yg)("inlineCode",{parentName:"p"},"platform_instance")," field in the recipe should be set to the dbt project name."),(0,n.yg)("p",null,"For example, if you have two dbt projects ",(0,n.yg)("inlineCode",{parentName:"p"},"analytics")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"data_mart"),", you would have two ingestion recipes.\nIf you have models in the ",(0,n.yg)("inlineCode",{parentName:"p"},"data_mart")," project that are used as sources in the ",(0,n.yg)("inlineCode",{parentName:"p"},"analytics")," project, the lineage will be automatically captured."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"# Analytics dbt project\nsource:\n  type: dbt\n  config:\n    platform_instance: analytics\n    target_platform: postgres\n    manifest_path: analytics/target/manifest.json\n    catalog_path: analytics/target/catalog.json\n    # ... other configs\n")),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"# Data Mart dbt project\nsource:\n  type: dbt\n  config:\n    platform_instance: data_mart\n    target_platform: postgres\n    manifest_path: data_mart/target/manifest.json\n    catalog_path: data_mart/target/catalog.json\n    # ... other configs\n")),(0,n.yg)("p",null,'If you have models that have tons of sources from other projects listed in the "Composed Of" section, it may also make sense to hide sources.'),(0,n.yg)("h3",{id:"reducing-composed-of-sprawl-by-hiding-sources"},'Reducing "composed of" sprawl by hiding sources'),(0,n.yg)("p",null,'When many dbt projects use a single table as a source, the "Composed Of" relationships can become very large and difficult to navigate\nand extra source nodes can clutter the lineage graph.'),(0,n.yg)("p",null,"This is particularly useful for multi-project setups, but can be useful in single-project setups as well."),(0,n.yg)("p",null,"The benefit is that your entire dbt estate becomes much easier to navigate, and the borders between projects less noticeable.\nThe downside is that we will not pick up any documentation or meta mappings applied to dbt sources."),(0,n.yg)("p",null,"To enable this, set ",(0,n.yg)("inlineCode",{parentName:"p"},"entities_enabled.sources: No")," and ",(0,n.yg)("inlineCode",{parentName:"p"},"skip_sources_in_lineage: true")," in your dbt source config:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},"source:\n  type: dbt\n  config:\n    platform_instance: analytics\n    target_platform: postgres\n    manifest_path: analytics/target/manifest.json\n    catalog_path: analytics/target/catalog.json\n    # ... other configs\n    entities_enabled:\n      sources: No\n    skip_sources_in_lineage: true\n")),(0,n.yg)("p",null,"[Experimental]"," It's also possible to use ",(0,n.yg)("inlineCode",{parentName:"p"},"skip_sources_in_lineage: true")," without disabling sources entirely. If you do this, sources will not participate in the lineage graph - they'll have upstreams but no downstreams. However, they will still contribute to docs, tags, etc to the warehouse entity."),(0,n.yg)("h3",{id:"semantic-views"},"Semantic Views"),(0,n.yg)("p",null,"DataHub can ingest dbt models that have been materialized as ",(0,n.yg)("inlineCode",{parentName:"p"},"semantic_view")," objects, a pattern used to define a semantic layer directly in warehouses like Snowflake."),(0,n.yg)("h4",{id:"what-are-materialized-semantic-views"},"What are Materialized Semantic Views?"),(0,n.yg)("p",null,"A materialized ",(0,n.yg)("a",{parentName:"p",href:"https://docs.snowflake.com/en/user-guide/views-semantic/overview"},"semantic view")," is a dbt model (a ",(0,n.yg)("inlineCode",{parentName:"p"},".sql")," file) that uses the ",(0,n.yg)("inlineCode",{parentName:"p"},"materialized='semantic_view'")," configuration via the ",(0,n.yg)("a",{parentName:"p",href:"https://github.com/Snowflake-Labs/dbt_semantic_view"},"dbt_semantic_view package"),". This creates a ",(0,n.yg)("inlineCode",{parentName:"p"},"SEMANTIC VIEW")," object in Snowflake, containing a rich set of metadata including dimensions and metrics."),(0,n.yg)("p",null,"When you define a dbt model as a semantic view:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-sql"},"-- models/sales_analytics.sql\n{{ config(\n    materialized='semantic_view'\n) }}\n\nTABLES (\n    OrdersTable AS {{ source('coffee_shop_source', 'ORDERS') }}\n)\nDIMENSIONS (\n    OrdersTable.CUSTOMER_ID AS CUSTOMER_ID\n)\nMETRICS (\n    OrdersTable.GROSS_REVENUE AS SUM(ORDER_TOTAL)\n)\n")),(0,n.yg)("p",null,"DataHub will:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Create a dataset with the subtype ",(0,n.yg)("inlineCode",{parentName:"li"},"Semantic View"),"."),(0,n.yg)("li",{parentName:"ol"},"Create sibling relationships to the underlying Snowflake ",(0,n.yg)("inlineCode",{parentName:"li"},"SEMANTIC VIEW")," object."),(0,n.yg)("li",{parentName:"ol"},"Extract column-level lineage from the semantic view's DDL.")),(0,n.yg)("h4",{id:"configuration"},"Configuration"),(0,n.yg)("p",null,"Semantic views are dbt models with ",(0,n.yg)("inlineCode",{parentName:"p"},"materialized='semantic_view'"),". They are emitted by default along with other models when ",(0,n.yg)("inlineCode",{parentName:"p"},"entities_enabled.models: Yes")," (the default)."),(0,n.yg)("h4",{id:"how-semantic-views-appear-in-datahub"},"How Semantic Views Appear in DataHub"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Subtype"),": Datasets are tagged with the subtype ",(0,n.yg)("inlineCode",{parentName:"li"},"Semantic View"),"."),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("strong",{parentName:"li"},"Lineage"),": Upstream lineage to the source dbt model is created, with column-level lineage where available.")),(0,n.yg)("h4",{id:"column-level-lineage-for-snowflake-semantic-views"},"Column-Level Lineage for Snowflake Semantic Views"),(0,n.yg)("p",null,"For dbt models materialized as semantic views in Snowflake, DataHub can extract column-level lineage from the compiled DDL. This requires:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},"Using Snowflake as the ",(0,n.yg)("inlineCode",{parentName:"li"},"target_platform"),"."),(0,n.yg)("li",{parentName:"ol"},"Having the ",(0,n.yg)("inlineCode",{parentName:"li"},"compiled_code")," for the model available in the dbt manifest or dbt Cloud API.")),(0,n.yg)("p",null,"If these conditions are not met, warnings will appear in the ingestion report:"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Condition"),(0,n.yg)("th",{parentName:"tr",align:null},"Warning"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Non-Snowflake adapter"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"Semantic View CLL Unsupported Adapter"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Missing ",(0,n.yg)("inlineCode",{parentName:"td"},"compiled_code")),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"Semantic View Missing compiled_code"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Empty CLL results"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"Semantic View CLL Empty"))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Parsing failure"),(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("inlineCode",{parentName:"td"},"Semantic View CLL Parsing Failed"))))),(0,n.yg)("blockquote",null,(0,n.yg)("p",{parentName:"blockquote"},(0,n.yg)("strong",{parentName:"p"},"Note: Limitations")),(0,n.yg)("p",{parentName:"blockquote"},"Column-level lineage is currently only supported for Snowflake semantic views, as it relies on parsing the Snowflake-specific DDL.")),(0,n.yg)("h3",{id:"code-coordinates"},"Code Coordinates"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Class Name: ",(0,n.yg)("inlineCode",{parentName:"li"},"datahub.ingestion.source.dbt.dbt_core.DBTCoreSource")),(0,n.yg)("li",{parentName:"ul"},"Browse on ",(0,n.yg)("a",{parentName:"li",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dbt/dbt_core.py"},"GitHub"))),(0,n.yg)("h2",{id:"module-dbt-cloud"},"Module ",(0,n.yg)("inlineCode",{parentName:"h2"},"dbt-cloud")),(0,n.yg)("p",null,(0,n.yg)("img",{parentName:"p",src:"https://img.shields.io/badge/support%20status-certified-brightgreen",alt:"Certified"})),(0,n.yg)("h3",{id:"important-capabilities-1"},"Important Capabilities"),(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:null},"Capability"),(0,n.yg)("th",{parentName:"tr",align:null},"Status"),(0,n.yg)("th",{parentName:"tr",align:null},"Notes"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Column-level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default, configure using ",(0,n.yg)("inlineCode",{parentName:"td"},"include_column_lineage"),".")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},(0,n.yg)("a",{parentName:"td",href:"/docs/metadata-ingestion/docs/dev_guides/stateful#stale-entity-removal"},"Detect Deleted Entities")),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default via stateful ingestion.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Table-Level Lineage"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:null},"Test Connection"),(0,n.yg)("td",{parentName:"tr",align:null},"\u2705"),(0,n.yg)("td",{parentName:"tr",align:null},"Enabled by default.")))),(0,n.yg)("h3",{id:"setup-1"},"Setup"),(0,n.yg)("p",null,"This source pulls dbt metadata directly from the dbt Cloud APIs."),(0,n.yg)("p",null,"Create a ",(0,n.yg)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/dbt-cloud-apis/service-tokens"},"service account token"),' with the "Metadata Only" permission.\nThis is a read-only permission.'),(0,n.yg)("h4",{id:"operating-modes"},"Operating Modes"),(0,n.yg)("p",null,"The dbt Cloud source supports two modes of operation:"),(0,n.yg)("h5",{id:"1-explicit-mode-default"},"1. Explicit Mode (Default)"),(0,n.yg)("p",null,'Specify a single dbt Cloud job to ingest metadata from. You\'ll need to have a dbt Cloud job set up to run your dbt project, and "Generate docs on run" should be enabled.'),(0,n.yg)("p",null,"Note: As this is ingesting only one job, we expect it to process all/most of the models, or else multiple job ingestion might be required."),(0,n.yg)("p",null,'To get the required IDs, go to the job details page (this is the one with the "Run History" table), and look at the URL.\nIt should look something like this: ',(0,n.yg)("a",{parentName:"p",href:"https://cloud.getdbt.com/next/deploy/107298/projects/175705/jobs/148094"},"https://cloud.getdbt.com/next/deploy/107298/projects/175705/jobs/148094"),".\nIn this example, the account ID is 107298, the project ID is 175705, and the job ID is 148094."),(0,n.yg)("h5",{id:"2-auto-discovery-mode"},"2. Auto-Discovery Mode"),(0,n.yg)("p",null,"Automatically discovers and ingests metadata from all eligible jobs in a dbt Cloud project. This mode:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Discovers all jobs in the specified project's ",(0,n.yg)("strong",{parentName:"li"},"production environment only")),(0,n.yg)("li",{parentName:"ul"},"Filters to jobs with ",(0,n.yg)("strong",{parentName:"li"},'"Generate docs on run" enabled')," (",(0,n.yg)("inlineCode",{parentName:"li"},"generate_docs=True"),")"),(0,n.yg)("li",{parentName:"ul"},"Always uses the ",(0,n.yg)("strong",{parentName:"li"},"latest run")," for each job (ignores ",(0,n.yg)("inlineCode",{parentName:"li"},"run_id")," configuration)"),(0,n.yg)("li",{parentName:"ul"},"Supports optional regex-based filtering to include/exclude specific job IDs"),(0,n.yg)("li",{parentName:"ul"},"Ingests metadata from multiple jobs in a single run")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"When to use auto-discovery:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"You have multiple dbt Cloud jobs in a project and want to ingest all of them"),(0,n.yg)("li",{parentName:"ul"},"You want to automatically pick up new jobs without updating configuration")),(0,n.yg)("p",null,(0,n.yg)("strong",{parentName:"p"},"Requirements:")),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Jobs must be in the production environment"),(0,n.yg)("li",{parentName:"ul"},'Jobs must have "Generate docs on run" enabled')),(0,n.yg)("h3",{id:"cli-based-ingestion-1"},"CLI based Ingestion"),(0,n.yg)("h3",{id:"starter-recipe-1"},"Starter Recipe"),(0,n.yg)("p",null,"Check out the following recipe to get started with ingestion! See ",(0,n.yg)("a",{parentName:"p",href:"#config-details"},"below")," for full configuration options."),(0,n.yg)("p",null,"For general pointers on writing and running a recipe, see our ",(0,n.yg)("a",{parentName:"p",href:"/docs/metadata-ingestion#recipes"},"main recipe guide"),"."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-yaml"},'source:\n  type: "dbt-cloud"\n  config:\n    token: ${DBT_CLOUD_TOKEN}\n\n    # In the URL https://cloud.getdbt.com/next/deploy/107298/projects/175705/jobs/148094,\n    # 107298 is the account_id, 175705 is the project_id, and 148094 is the job_id\n\n    account_id: "${DBT_ACCOUNT_ID}" # set to your dbt cloud account id\n    project_id: "${DBT_PROJECT_ID}" # set to your dbt cloud project id\n\n    # Mode 1: Explicit Mode (specify a single job)\n    job_id: "${DBT_JOB_ID}" # set to your dbt cloud job id\n    run_id: # optional: set to a specific dbt cloud run id. Defaults to the latest run\n\n    # Mode 2: Auto-Discovery Mode (automatically discover all eligible jobs)\n    # Uncomment the section below to enable auto-discovery\n    # Note: When auto_discovery is enabled, job_id can be omitted (will be ignored if provided)\n    # and run_id is ignored (always uses the latest run)\n    # auto_discovery:\n    #   enabled: true\n    #   job_id_pattern: # optional\n    #     allow:\n    #       - ".*"  # regex pattern to include jobs (default: include all)\n    #     # deny:\n    #     #   - "test.*"  # optional: regex pattern to exclude specific jobs\n\n    target_platform: "${TARGET_PLATFORM_ID}" # e.g. bigquery/postgres/snowflake/etc.\n\n# sink configs\n\n')),(0,n.yg)("h3",{id:"config-details-1"},"Config Details"),(0,n.yg)(i.A,{mdxType:"Tabs"},(0,n.yg)(l.A,{value:"options",label:"Options",default:!0,mdxType:"TabItem"},(0,n.yg)("p",null,"Note that a ",(0,n.yg)("inlineCode",{parentName:"p"},".")," is used to denote nested fields in the YAML recipe."),(0,n.yg)("div",{className:"config-table"},(0,n.yg)("table",null,(0,n.yg)("thead",{parentName:"table"},(0,n.yg)("tr",{parentName:"thead"},(0,n.yg)("th",{parentName:"tr",align:"left"},"Field"),(0,n.yg)("th",{parentName:"tr",align:"left"},"Description"))),(0,n.yg)("tbody",{parentName:"table"},(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"account_id"),"\xa0",(0,n.yg)("abbr",{title:"Required"},"\u2705"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The DBT Cloud account ID to use.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"project_id"),"\xa0",(0,n.yg)("abbr",{title:"Required"},"\u2705"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"integer"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The dbt Cloud project ID to use.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"target_platform"),"\xa0",(0,n.yg)("abbr",{title:"Required"},"\u2705"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The platform that dbt is loading onto. (e.g. bigquery / redshift / postgres etc.)")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"token"),"\xa0",(0,n.yg)("abbr",{title:"Required"},"\u2705"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The API token to use to authenticate with DBT Cloud.")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"access_url"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The base URL of the dbt Cloud instance to use. This should be the URL you use to access the dbt Cloud UI. It should include the scheme (http/https) and not include a trailing slash. See the access url for your dbt Cloud region here: ",(0,n.yg)("a",{parentName:"td",href:"https://docs.getdbt.com/docs/cloud/about-cloud/regions-ip-addresses"},"https://docs.getdbt.com/docs/cloud/about-cloud/regions-ip-addresses")," ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},(0,n.yg)("a",{parentName:"td",href:"https://cloud.getdbt.com"},"https://cloud.getdbt.com"))))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"column_meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against dbt column meta properties. Refer to the section below on dbt meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"convert_column_urns_to_lowercase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, converts column URNs to lowercase to ensure cross-platform compatibility. If ",(0,n.yg)("inlineCode",{parentName:"td"},"target_platform")," is Snowflake, the default is True. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"dbt_is_primary_sibling"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Experimental: Controls sibling relationship primary designation between dbt entities and target platform entities. When True (default), dbt entities are primary and target platform entities are secondary. When False, target platform entities are primary and dbt entities are secondary. Uses aspect patches for precise control. Requires DataHub server 1.3.0+. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"drop_duplicate_sources"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, drops sources that have the same name in the target platform as a model. This ensures that lineage is generated reliably, but will lose any documentation associated only with the source. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, applies the mappings that are defined through the meta_mapping directives. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_owner_extraction"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, ownership info will be extracted from the dbt meta ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"enable_query_tag_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, applies the mappings that are defined through the ",(0,n.yg)("inlineCode",{parentName:"td"},"query_tag_mapping")," directives. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"external_url_mode"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "explore", "ide" ',(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"explore")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_column_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, column-level lineage will be extracted from the dbt node definition. Requires ",(0,n.yg)("inlineCode",{parentName:"td"},"infer_dbt_schemas")," to be enabled. If you run into issues where the column name casing does not match up with properly, providing a datahub_api or using the rest sink will improve accuracy. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_compiled_code"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, includes the compiled code in the emitted metadata. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_database_name"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to add database name to the table urn. Set to False to skip it for engines like AWS Athena where it's not required. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"include_env_in_assertion_guid"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prior to version 0.9.4.2, the assertion GUIDs did not include the environment. If you're using multiple dbt ingestion that are only distinguished by env, then you should set this flag to True. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"incremental_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, emits incremental/patch lineage for non-dbt entities. When disabled, re-states lineage on each run. This would also require enabling 'incremental",(0,n.yg)("em",{parentName:"td"},"lineage' in the counterpart warehouse ingestion (_e.g.")," BigQuery, Redshift, etc). ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"infer_dbt_schemas"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, schemas will be inferred from the dbt node definition. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"job_id"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The ID of the job to ingest metadata from. Required in explicit mode (when auto_discovery is disabled). ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"meta_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against dbt meta properties. Refer to the section below on dbt meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"metadata_endpoint"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The dbt Cloud metadata API endpoint. If not provided, we will try to infer it from the access_url. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},(0,n.yg)("a",{parentName:"td",href:"https://metadata.cloud.getdbt.com/graphql"},"https://metadata.cloud.getdbt.com/graphql"))))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"owner_extraction_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Regex string to extract owner from the dbt node using the ",(0,n.yg)("inlineCode",{parentName:"td"},"(?P<name>...) syntax")," of the ",(0,n.yg)("a",{parentName:"td",href:"https://docs.python.org/3/library/re.html#match-objects"},"match object"),", where the group name must be ",(0,n.yg)("inlineCode",{parentName:"td"},"owner"),". Examples: (1)",(0,n.yg)("inlineCode",{parentName:"td"},'r"(?P<owner>(.*)): (\\w+) (\\w+)"')," will extract ",(0,n.yg)("inlineCode",{parentName:"td"},"jdoe")," as the owner from ",(0,n.yg)("inlineCode",{parentName:"td"},'"jdoe: John Doe"')," (2) ",(0,n.yg)("inlineCode",{parentName:"td"},'r"@(?P<owner>(.*))"')," will extract ",(0,n.yg)("inlineCode",{parentName:"td"},"alice")," as the owner from ",(0,n.yg)("inlineCode",{parentName:"td"},'"@alice"'),". ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"platform_instance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See ",(0,n.yg)("a",{parentName:"td",href:"https://docs.datahub.com/docs/platform-instances/"},"https://docs.datahub.com/docs/platform-instances/")," for more details. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"prefer_sql_parser_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Normally we use dbt's metadata to generate table lineage. When enabled, we prefer results from the SQL parser when generating lineage instead. This can be useful when dbt models reference tables directly, instead of using the ref() macro. This requires that ",(0,n.yg)("inlineCode",{parentName:"td"},"skip_sources_in_lineage")," is enabled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"query_tag_mapping"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"object"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"mapping rules that will be executed against dbt query_tag meta properties. Refer to the section below on dbt meta automated mappings. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"{","}")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"run_id"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of integer, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The ID of the run to ingest metadata from. If not specified, defaults to the latest run. In auto-discovery mode, always uses the latest run for each job. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"skip_sources_in_lineage"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"[Experimental]"," When enabled, dbt sources will not be included in the lineage graph. Requires that ",(0,n.yg)("inlineCode",{parentName:"td"},"entities_enabled.sources")," is set to ",(0,n.yg)("inlineCode",{parentName:"td"},"NO"),". This is mainly useful when you have multiple, interdependent dbt projects.  ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"strip_user_ids_from_email"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether or not to strip email id while adding owners using dbt meta actions. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"tag_prefix"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prefix added to tags during ingestion. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"dbt:")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"target_platform_instance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of string, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"The platform instance for the platform that dbt is operating on. Use this if you have multiple instances of the same platform (e.g. redshift) and need to distinguish between them. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"test_warnings_are_errors"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"When enabled, dbt test warnings will be treated as failures. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"use_identifiers"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Use model identifier instead of model name if defined (if not, default to model name). ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"write_semantics"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'Whether the new tags, terms and owners to be added will override the existing ones added only by this source or not. Value for this config can be "PATCH" or "OVERRIDE" ',(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"PATCH")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"env"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"string"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Environment to use in namespace when constructing URNs. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"PROD")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"auto_discovery"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of AutoDiscoveryConfig, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Auto-discovery configuration. When enabled, automatically discovers jobs for the specified project. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"auto_discovery."),(0,n.yg)("span",{className:"path-main"},"enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Enable/disable auto-discovery mode. When enabled, discovers jobs for the specified project. Only production jobs with generate_docs=True are ingested. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"auto_discovery."),(0,n.yg)("span",{className:"path-main"},"job_id_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"auto_discovery.job_id_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"entities_enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"DBTEntitiesEnabled"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Controls which dbt entities are going to be emitted by this source")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"model_performance"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"models"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"seeds"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"snapshots"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"sources"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"test_definitions"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"entities_enabled."),(0,n.yg)("span",{className:"path-main"},"test_results"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"Enum"))),(0,n.yg)("td",{parentName:"tr",align:"left"},'One of: "YES", "NO", "ONLY"')),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"materialized_node_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"MaterializedNodePatternConfig"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Configuration for filtering materialized nodes based on their physical location")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern."),(0,n.yg)("span",{className:"path-main"},"database_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern.database_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern."),(0,n.yg)("span",{className:"path-main"},"schema_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern.schema_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern."),(0,n.yg)("span",{className:"path-main"},"table_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"materialized_node_pattern.table_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"node_name_pattern"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"AllowDenyPattern"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"A class to store allow deny regexes")),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"node_name_pattern."),(0,n.yg)("span",{className:"path-main"},"ignoreCase"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of boolean, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether to ignore case sensitivity during pattern matching. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-main"},"stateful_ingestion"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"One of StatefulStaleMetadataRemovalConfig, null"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"DBT Stateful Ingestion Config. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"None")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"enabled"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or ",(0,n.yg)("inlineCode",{parentName:"td"},"datahub_api")," is specified, otherwise False ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"False")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"fail_safe_threshold"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"number"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the 'fail_safe_threshold'. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"75.0")))),(0,n.yg)("tr",{parentName:"tbody"},(0,n.yg)("td",{parentName:"tr",align:"left"},(0,n.yg)("div",{className:"path-line"},(0,n.yg)("span",{className:"path-prefix"},"stateful_ingestion."),(0,n.yg)("span",{className:"path-main"},"remove_stale_metadata"))," ",(0,n.yg)("div",{className:"type-name-line"},(0,n.yg)("span",{className:"type-name"},"boolean"))),(0,n.yg)("td",{parentName:"tr",align:"left"},"Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled. ",(0,n.yg)("div",{className:"default-line default-line-with-docs"},"Default: ",(0,n.yg)("span",{className:"default-value"},"True")))))))),(0,n.yg)(l.A,{value:"schema",label:"Schema",mdxType:"TabItem"},(0,n.yg)("p",null,"The ",(0,n.yg)("a",{parentName:"p",href:"https://json-schema.org/"},"JSONSchema")," for this configuration is inlined below."),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-javascript"},'{\n  "$defs": {\n    "AllowDenyPattern": {\n      "additionalProperties": false,\n      "description": "A class to store allow deny regexes",\n      "properties": {\n        "allow": {\n          "default": [\n            ".*"\n          ],\n          "description": "List of regex patterns to include in ingestion",\n          "items": {\n            "type": "string"\n          },\n          "title": "Allow",\n          "type": "array"\n        },\n        "deny": {\n          "default": [],\n          "description": "List of regex patterns to exclude from ingestion.",\n          "items": {\n            "type": "string"\n          },\n          "title": "Deny",\n          "type": "array"\n        },\n        "ignoreCase": {\n          "anyOf": [\n            {\n              "type": "boolean"\n            },\n            {\n              "type": "null"\n            }\n          ],\n          "default": true,\n          "description": "Whether to ignore case sensitivity during pattern matching.",\n          "title": "Ignorecase"\n        }\n      },\n      "title": "AllowDenyPattern",\n      "type": "object"\n    },\n    "AutoDiscoveryConfig": {\n      "additionalProperties": false,\n      "description": "Configuration for auto-discovery mode that automatically discovers jobs for a project.\\nRef: DBT Jobs: http://docs.getdbt.com/docs/deploy/jobs\\nTODO: The configuration is oraganised this way to allow for future expansion to project discovery at account level.",\n      "properties": {\n        "enabled": {\n          "default": false,\n          "description": "Enable/disable auto-discovery mode. When enabled, discovers jobs for the specified project. Only production jobs with generate_docs=True are ingested.",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "job_id_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "description": "Regex patterns to filter jobs by job_id when auto-discovering."\n        }\n      },\n      "title": "AutoDiscoveryConfig",\n      "type": "object"\n    },\n    "DBTEntitiesEnabled": {\n      "additionalProperties": false,\n      "description": "Controls which dbt entities are going to be emitted by this source",\n      "properties": {\n        "models": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt models when set to Yes or Only"\n        },\n        "sources": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt sources when set to Yes or Only"\n        },\n        "seeds": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt seeds when set to Yes or Only"\n        },\n        "snapshots": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for dbt snapshots when set to Yes or Only"\n        },\n        "test_definitions": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for test definitions when enabled when set to Yes or Only"\n        },\n        "test_results": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit metadata for test results when set to Yes or Only"\n        },\n        "model_performance": {\n          "$ref": "#/$defs/EmitDirective",\n          "default": "YES",\n          "description": "Emit model performance metadata when set to Yes or Only. Only supported with dbt core."\n        }\n      },\n      "title": "DBTEntitiesEnabled",\n      "type": "object"\n    },\n    "EmitDirective": {\n      "description": "A holder for directives for emission for specific types of entities",\n      "enum": [\n        "YES",\n        "NO",\n        "ONLY"\n      ],\n      "title": "EmitDirective",\n      "type": "string"\n    },\n    "MaterializedNodePatternConfig": {\n      "additionalProperties": false,\n      "description": "Configuration for filtering materialized nodes based on their physical location",\n      "properties": {\n        "database_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns for database names to filter materialized nodes."\n        },\n        "schema_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns for schema names in format \'{database}.{schema}\' to filter materialized nodes."\n        },\n        "table_pattern": {\n          "$ref": "#/$defs/AllowDenyPattern",\n          "default": {\n            "allow": [\n              ".*"\n            ],\n            "deny": [],\n            "ignoreCase": true\n          },\n          "description": "Regex patterns for table/view names in format \'{database}.{schema}.{table}\' to filter materialized nodes."\n        }\n      },\n      "title": "MaterializedNodePatternConfig",\n      "type": "object"\n    },\n    "StatefulStaleMetadataRemovalConfig": {\n      "additionalProperties": false,\n      "description": "Base specialized config for Stateful Ingestion with stale metadata removal capability.",\n      "properties": {\n        "enabled": {\n          "default": false,\n          "description": "Whether or not to enable stateful ingest. Default: True if a pipeline_name is set and either a datahub-rest sink or `datahub_api` is specified, otherwise False",\n          "title": "Enabled",\n          "type": "boolean"\n        },\n        "remove_stale_metadata": {\n          "default": true,\n          "description": "Soft-deletes the entities present in the last successful run but missing in the current run with stateful_ingestion enabled.",\n          "title": "Remove Stale Metadata",\n          "type": "boolean"\n        },\n        "fail_safe_threshold": {\n          "default": 75.0,\n          "description": "Prevents large amount of soft deletes & the state from committing from accidental changes to the source configuration if the relative change percent in entities compared to the previous state is above the \'fail_safe_threshold\'.",\n          "maximum": 100.0,\n          "minimum": 0.0,\n          "title": "Fail Safe Threshold",\n          "type": "number"\n        }\n      },\n      "title": "StatefulStaleMetadataRemovalConfig",\n      "type": "object"\n    }\n  },\n  "additionalProperties": false,\n  "properties": {\n    "incremental_lineage": {\n      "default": true,\n      "description": "When enabled, emits incremental/patch lineage for non-dbt entities. When disabled, re-states lineage on each run. This would also require enabling \'incremental_lineage\' in the counterpart warehouse ingestion (_e.g._ BigQuery, Redshift, etc).",\n      "title": "Incremental Lineage",\n      "type": "boolean"\n    },\n    "env": {\n      "default": "PROD",\n      "description": "Environment to use in namespace when constructing URNs.",\n      "title": "Env",\n      "type": "string"\n    },\n    "platform_instance": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The instance of the platform that all assets produced by this recipe belong to. This should be unique within the platform. See https://docs.datahub.com/docs/platform-instances/ for more details.",\n      "title": "Platform Instance"\n    },\n    "stateful_ingestion": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/StatefulStaleMetadataRemovalConfig"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "DBT Stateful Ingestion Config."\n    },\n    "target_platform": {\n      "description": "The platform that dbt is loading onto. (e.g. bigquery / redshift / postgres etc.)",\n      "title": "Target Platform",\n      "type": "string"\n    },\n    "target_platform_instance": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The platform instance for the platform that dbt is operating on. Use this if you have multiple instances of the same platform (e.g. redshift) and need to distinguish between them.",\n      "title": "Target Platform Instance"\n    },\n    "use_identifiers": {\n      "default": false,\n      "description": "Use model identifier instead of model name if defined (if not, default to model name).",\n      "title": "Use Identifiers",\n      "type": "boolean"\n    },\n    "entities_enabled": {\n      "$ref": "#/$defs/DBTEntitiesEnabled",\n      "default": {\n        "models": "YES",\n        "sources": "YES",\n        "seeds": "YES",\n        "snapshots": "YES",\n        "test_definitions": "YES",\n        "test_results": "YES",\n        "model_performance": "YES"\n      },\n      "description": "Controls for enabling / disabling metadata emission for different dbt entities (models, test definitions, test results, etc.)"\n    },\n    "prefer_sql_parser_lineage": {\n      "default": false,\n      "description": "Normally we use dbt\'s metadata to generate table lineage. When enabled, we prefer results from the SQL parser when generating lineage instead. This can be useful when dbt models reference tables directly, instead of using the ref() macro. This requires that `skip_sources_in_lineage` is enabled.",\n      "title": "Prefer Sql Parser Lineage",\n      "type": "boolean"\n    },\n    "skip_sources_in_lineage": {\n      "default": false,\n      "description": "[Experimental] When enabled, dbt sources will not be included in the lineage graph. Requires that `entities_enabled.sources` is set to `NO`. This is mainly useful when you have multiple, interdependent dbt projects. ",\n      "title": "Skip Sources In Lineage",\n      "type": "boolean"\n    },\n    "tag_prefix": {\n      "default": "dbt:",\n      "description": "Prefix added to tags during ingestion.",\n      "title": "Tag Prefix",\n      "type": "string"\n    },\n    "node_name_pattern": {\n      "$ref": "#/$defs/AllowDenyPattern",\n      "default": {\n        "allow": [\n          ".*"\n        ],\n        "deny": [],\n        "ignoreCase": true\n      },\n      "description": "regex patterns for dbt model names to filter in ingestion."\n    },\n    "materialized_node_pattern": {\n      "$ref": "#/$defs/MaterializedNodePatternConfig",\n      "default": {\n        "database_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        },\n        "schema_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        },\n        "table_pattern": {\n          "allow": [\n            ".*"\n          ],\n          "deny": [],\n          "ignoreCase": true\n        }\n      },\n      "description": "Advanced filtering for materialized nodes based on their physical database location. Provides fine-grained control over database.schema.table patterns for catalog consistency."\n    },\n    "meta_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against dbt meta properties. Refer to the section below on dbt meta automated mappings.",\n      "title": "Meta Mapping",\n      "type": "object"\n    },\n    "column_meta_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against dbt column meta properties. Refer to the section below on dbt meta automated mappings.",\n      "title": "Column Meta Mapping",\n      "type": "object"\n    },\n    "enable_meta_mapping": {\n      "default": true,\n      "description": "When enabled, applies the mappings that are defined through the meta_mapping directives.",\n      "title": "Enable Meta Mapping",\n      "type": "boolean"\n    },\n    "query_tag_mapping": {\n      "additionalProperties": true,\n      "default": {},\n      "description": "mapping rules that will be executed against dbt query_tag meta properties. Refer to the section below on dbt meta automated mappings.",\n      "title": "Query Tag Mapping",\n      "type": "object"\n    },\n    "enable_query_tag_mapping": {\n      "default": true,\n      "description": "When enabled, applies the mappings that are defined through the `query_tag_mapping` directives.",\n      "title": "Enable Query Tag Mapping",\n      "type": "boolean"\n    },\n    "write_semantics": {\n      "default": "PATCH",\n      "description": "Whether the new tags, terms and owners to be added will override the existing ones added only by this source or not. Value for this config can be \\"PATCH\\" or \\"OVERRIDE\\"",\n      "title": "Write Semantics",\n      "type": "string"\n    },\n    "strip_user_ids_from_email": {\n      "default": false,\n      "description": "Whether or not to strip email id while adding owners using dbt meta actions.",\n      "title": "Strip User Ids From Email",\n      "type": "boolean"\n    },\n    "enable_owner_extraction": {\n      "default": true,\n      "description": "When enabled, ownership info will be extracted from the dbt meta",\n      "title": "Enable Owner Extraction",\n      "type": "boolean"\n    },\n    "owner_extraction_pattern": {\n      "anyOf": [\n        {\n          "type": "string"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Regex string to extract owner from the dbt node using the `(?P<name>...) syntax` of the [match object](https://docs.python.org/3/library/re.html#match-objects), where the group name must be `owner`. Examples: (1)`r\\"(?P<owner>(.*)): (\\\\w+) (\\\\w+)\\"` will extract `jdoe` as the owner from `\\"jdoe: John Doe\\"` (2) `r\\"@(?P<owner>(.*))\\"` will extract `alice` as the owner from `\\"@alice\\"`.",\n      "title": "Owner Extraction Pattern"\n    },\n    "include_env_in_assertion_guid": {\n      "default": false,\n      "description": "Prior to version 0.9.4.2, the assertion GUIDs did not include the environment. If you\'re using multiple dbt ingestion that are only distinguished by env, then you should set this flag to True.",\n      "title": "Include Env In Assertion Guid",\n      "type": "boolean"\n    },\n    "convert_column_urns_to_lowercase": {\n      "default": false,\n      "description": "When enabled, converts column URNs to lowercase to ensure cross-platform compatibility. If `target_platform` is Snowflake, the default is True.",\n      "title": "Convert Column Urns To Lowercase",\n      "type": "boolean"\n    },\n    "test_warnings_are_errors": {\n      "default": false,\n      "description": "When enabled, dbt test warnings will be treated as failures.",\n      "title": "Test Warnings Are Errors",\n      "type": "boolean"\n    },\n    "infer_dbt_schemas": {\n      "default": true,\n      "description": "When enabled, schemas will be inferred from the dbt node definition.",\n      "title": "Infer Dbt Schemas",\n      "type": "boolean"\n    },\n    "include_column_lineage": {\n      "default": true,\n      "description": "When enabled, column-level lineage will be extracted from the dbt node definition. Requires `infer_dbt_schemas` to be enabled. If you run into issues where the column name casing does not match up with properly, providing a datahub_api or using the rest sink will improve accuracy.",\n      "title": "Include Column Lineage",\n      "type": "boolean"\n    },\n    "include_compiled_code": {\n      "default": true,\n      "description": "When enabled, includes the compiled code in the emitted metadata.",\n      "title": "Include Compiled Code",\n      "type": "boolean"\n    },\n    "include_database_name": {\n      "default": true,\n      "description": "Whether to add database name to the table urn. Set to False to skip it for engines like AWS Athena where it\'s not required.",\n      "title": "Include Database Name",\n      "type": "boolean"\n    },\n    "dbt_is_primary_sibling": {\n      "default": true,\n      "description": "Experimental: Controls sibling relationship primary designation between dbt entities and target platform entities. When True (default), dbt entities are primary and target platform entities are secondary. When False, target platform entities are primary and dbt entities are secondary. Uses aspect patches for precise control. Requires DataHub server 1.3.0+.",\n      "title": "Dbt Is Primary Sibling",\n      "type": "boolean"\n    },\n    "drop_duplicate_sources": {\n      "default": true,\n      "description": "When enabled, drops sources that have the same name in the target platform as a model. This ensures that lineage is generated reliably, but will lose any documentation associated only with the source.",\n      "title": "Drop Duplicate Sources",\n      "type": "boolean"\n    },\n    "access_url": {\n      "default": "https://cloud.getdbt.com",\n      "description": "The base URL of the dbt Cloud instance to use. This should be the URL you use to access the dbt Cloud UI. It should include the scheme (http/https) and not include a trailing slash. See the access url for your dbt Cloud region here: https://docs.getdbt.com/docs/cloud/about-cloud/regions-ip-addresses",\n      "title": "Access Url",\n      "type": "string"\n    },\n    "metadata_endpoint": {\n      "default": "https://metadata.cloud.getdbt.com/graphql",\n      "description": "The dbt Cloud metadata API endpoint. If not provided, we will try to infer it from the access_url.",\n      "title": "Metadata Endpoint",\n      "type": "string"\n    },\n    "token": {\n      "description": "The API token to use to authenticate with DBT Cloud.",\n      "title": "Token",\n      "type": "string"\n    },\n    "account_id": {\n      "description": "The DBT Cloud account ID to use.",\n      "title": "Account Id",\n      "type": "integer"\n    },\n    "project_id": {\n      "description": "The dbt Cloud project ID to use.",\n      "title": "Project Id",\n      "type": "integer"\n    },\n    "job_id": {\n      "anyOf": [\n        {\n          "type": "integer"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The ID of the job to ingest metadata from. Required in explicit mode (when auto_discovery is disabled).",\n      "title": "Job Id"\n    },\n    "run_id": {\n      "anyOf": [\n        {\n          "type": "integer"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "The ID of the run to ingest metadata from. If not specified, defaults to the latest run. In auto-discovery mode, always uses the latest run for each job.",\n      "title": "Run Id"\n    },\n    "auto_discovery": {\n      "anyOf": [\n        {\n          "$ref": "#/$defs/AutoDiscoveryConfig"\n        },\n        {\n          "type": "null"\n        }\n      ],\n      "default": null,\n      "description": "Auto-discovery configuration. When enabled, automatically discovers jobs for the specified project."\n    },\n    "external_url_mode": {\n      "default": "explore",\n      "description": "Where should the \\"View in dbt\\" link point to - either the \\"Explore\\" UI or the dbt Cloud IDE",\n      "enum": [\n        "explore",\n        "ide"\n      ],\n      "title": "External Url Mode",\n      "type": "string"\n    }\n  },\n  "required": [\n    "target_platform",\n    "token",\n    "account_id",\n    "project_id"\n  ],\n  "title": "DBTCloudConfig",\n  "type": "object"\n}\n')))),(0,n.yg)("h3",{id:"code-coordinates-1"},"Code Coordinates"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Class Name: ",(0,n.yg)("inlineCode",{parentName:"li"},"datahub.ingestion.source.dbt.dbt_cloud.DBTCloudSource")),(0,n.yg)("li",{parentName:"ul"},"Browse on ",(0,n.yg)("a",{parentName:"li",href:"https://github.com/datahub-project/datahub/blob/master/metadata-ingestion/src/datahub/ingestion/source/dbt/dbt_cloud.py"},"GitHub"))),(0,n.yg)("h2",null,"Questions"),(0,n.yg)("p",null,"If you've got any questions on configuring ingestion for dbt, feel free to ping us on ",(0,n.yg)("a",{parentName:"p",href:"https://datahub.com/slack"},"our Slack"),"."))}f.isMDXComponent=!0}}]);